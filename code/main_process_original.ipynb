{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b13ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_process.py\n",
    "# 主程序入口，进行数据加载、预处理、模型训练与测试，并评估分类准确率\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch import nn\n",
    "from data_loader import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from collections import Counter\n",
    "from autoencoder import *\n",
    "from evt import *\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb7b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Github\\Trident\\code\\data_loader.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.replace([np.inf, -np.inf], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Attack Type\n",
      "6     1440906\n",
      "11    1083360\n",
      "8      819305\n",
      "9      808928\n",
      "17     535121\n",
      "16     406024\n",
      "1      219809\n",
      "19     191353\n",
      "20     177756\n",
      "7       90510\n",
      "27      74423\n",
      "18      61784\n",
      "12      57249\n",
      "4       56535\n",
      "13      35955\n",
      "21      26834\n",
      "22      19656\n",
      "24      16493\n",
      "15      14358\n",
      "5        5673\n",
      "10       4692\n",
      "14       2639\n",
      "2        1187\n",
      "25       1097\n",
      "3        1055\n",
      "28        779\n",
      "0         659\n",
      "23        444\n",
      "26        277\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子，保证实验可复现\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# 解析命令行参数，支持自定义数据集名称\n",
    "default_data_name = 'demo'\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--data_name', type = str, default = default_data_name, help = 'data name')\n",
    "# args = parser.parse_args()\n",
    "# data_name = args.data_name\n",
    "data_name = default_data_name\n",
    "\n",
    "# 加载数据集，并进行标准化\n",
    "# data_load: 特征数据, label_load: 标签\n",
    "data_load, label_load = read_dataset(data_name)\n",
    "data_load = StandardScaler().fit_transform(data_load)\n",
    "\n",
    "# 统计每个类别的样本数，确定训练/测试划分\n",
    "count_number = Counter(label_load)\n",
    "min_num = np.array(list(count_number.values())).min()  # 最小类别样本数\n",
    "test_per_class = 260  # 每类测试样本数\n",
    "num_per_class = min_num - test_per_class  # 每类训练样本数\n",
    "dim = data_load.shape[1]  # 特征维度\n",
    "b_size = test_per_class   # 批量大小\n",
    "loss_func = nn.MSELoss()  # 损失函数\n",
    "\n",
    "sum_num = len(set(list((label_load))))  # 类别总数\n",
    "train_num = 1  # 训练类别数（只用一个类别做已知，其余为新类）\n",
    "newclass_num = sum_num - train_num  # 新类别数\n",
    "\n",
    "# 打乱数据顺序\n",
    "shun = list(range(data_load.shape[0]))\n",
    "random.shuffle(shun)\n",
    "data_load = data_load[shun]\n",
    "label_load = label_load[shun]\n",
    "\n",
    "# 随机排列类别索引\n",
    "allIndex = np.random.permutation(train_num + newclass_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb67499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct labels in 'gtlabel': [27. 16. 12. 22.  8.  9. 21.  0. 26. 13. 15. 11. 17.  1.  4.  5.  2. 24.\n",
      "  3. 23. 25. 18. 28. 20.  7. 10. 14. 19.  6.]\n"
     ]
    }
   ],
   "source": [
    "# 构建训练集（只包含已知类别）\n",
    "data = np.zeros((num_per_class * (train_num), dim))\n",
    "label = np.zeros(num_per_class * (train_num))\n",
    "for pos in range(train_num):\n",
    "    i = allIndex[pos]\n",
    "    data[pos * num_per_class:(pos + 1) * num_per_class,:] = data_load[label_load==i][0:num_per_class, :]\n",
    "    label[pos * num_per_class:(pos + 1) * num_per_class] = i\n",
    "\n",
    "\n",
    "# 构建流式测试集（包含所有类别，已知类标记为原标签，未知类标记为999）\n",
    "streamdata = np.zeros((test_per_class * (train_num + newclass_num), dim))\n",
    "streamlabel = np.zeros(test_per_class * (train_num + newclass_num))\n",
    "gtlabel = np.zeros(test_per_class * (train_num + newclass_num))\n",
    "for pos in range(train_num + newclass_num):\n",
    "    i = allIndex[pos]\n",
    "    streamdata[pos * test_per_class:(pos + 1) * test_per_class,:] = data_load[label_load==i][-test_per_class:, :]\n",
    "    gtlabel[pos * test_per_class:(pos + 1) * test_per_class] = i\n",
    "    if pos < train_num:\n",
    "        streamlabel[pos * test_per_class:(pos+1) * test_per_class] = i\n",
    "    else:\n",
    "        streamlabel[pos * test_per_class:(pos + 1) * test_per_class] = 999\n",
    "        \n",
    "# 输出 gtlabel 中按出现顺序的不同标签\n",
    "unique_labels = pd.Series(gtlabel).unique()\n",
    "print(\"Distinct labels in 'gtlabel':\", unique_labels)\n",
    "\n",
    "\n",
    "# 根据标签统计，筛选样本数大于50的类别\n",
    "# 返回当前存在的类别列表\n",
    "def make_lab(label):\n",
    "    xianyou = pd.DataFrame(label).value_counts()\n",
    "    curr_lab = []\n",
    "    for j1 in xianyou.keys():\n",
    "        if xianyou[j1] > 50:\n",
    "            curr_lab.append(j1[0])\n",
    "    return curr_lab\n",
    "\n",
    "# 针对每个类别训练自编码器模型，并用SPOT方法确定阈值\n",
    "# 返回模型列表、阈值列表、类别列表\n",
    "def train(data, label, curr_lab):\n",
    "    mod_ls = []\n",
    "    thred_ls = []\n",
    "    class_ls = []\n",
    "    batch = 10\n",
    "    epoch = 10\n",
    "    y_in, y1, y2, y3, y4 = data_load.shape[1], 256, 128, 64, 32\n",
    "    for i in curr_lab:\n",
    "        class_ls.append(i)\n",
    "        model = Autoencoder(y_in, y1, y2, y3, y4)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 5e-4)\n",
    "        # 训练自编码器\n",
    "        for i2 in range(epoch):\n",
    "            shun = list(range(data[label==i].shape[0]))\n",
    "            random.shuffle(shun)\n",
    "            for i3 in range(int(data[label==i].shape[0] / batch)):\n",
    "                data_input = torch.from_numpy(data[label==i][shun][i3 * batch : (i3+1) * batch]).float()\n",
    "                pred = model(data_input)\n",
    "                loss = loss_func(pred, data_input)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        mod_eva = model.eval()\n",
    "        mod_ls.append(model)\n",
    "        # 计算重构误差，用于阈值确定\n",
    "        mse_ls = []\n",
    "        for i4 in range(int(data[label==i].shape[0] / batch)):\n",
    "            data_input = torch.from_numpy(data[label==i][i4 * batch : (i4+1) * batch]).float()\n",
    "            pred = model(data_input)\n",
    "            for i5 in range(pred.shape[0]):\n",
    "                loss = loss_func(pred[i5], data_input[i5])\n",
    "                mse_ls.append(float(loss.detach().numpy()))\n",
    "        data_input = torch.from_numpy(data[label==i][(i4 + 1) * batch:]).float()\n",
    "        pred = model(data_input)\n",
    "        for i5 in range(pred.shape[0]):\n",
    "            loss = loss_func(pred[i5], data_input[i5])\n",
    "            mse_ls.append(float(loss.detach().numpy()))\n",
    "        loss_list_use = np.array(mse_ls)\n",
    "        # 对损失列表进行标准化处理以提高异常检测效果\n",
    "        loss_list_use = np.array(mse_ls)\n",
    "        q = 5e-2 # 风险参数，可调\n",
    "        s = SPOT(q)\n",
    "        s.fit(loss_list_use, loss_list_use)\n",
    "        s.initialize()\n",
    "        results = s.run_simp()\n",
    "        # 阈值选取\n",
    "        if results['thresholds'][0] > 0:\n",
    "            thred_ls.append(results['thresholds'][0])\n",
    "        else:\n",
    "            thred_ls.append(np.sort(s.init_data)[int(0.85 * s.init_data.size)])\n",
    "    return mod_ls, thred_ls, class_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f150f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing ===\n",
      "Current labels: [27.0, 16.0]\n",
      "*** Update model ***\n",
      "Number of models: 2\n",
      "Thresholds: [np.float64(0.07515961676836014), np.float64(0.016395680251651605)]\n",
      "Class labels: [27.0, 16.0]\n",
      "Current labels: [27.0, 12.0, 16.0]\n",
      "*** Update model ***\n",
      "Number of models: 3\n",
      "Thresholds: [np.float64(0.05633612349629402), np.float64(0.02620452320878401), np.float64(0.002226864919066429)]\n",
      "Class labels: [27.0, 12.0, 16.0]\n",
      "Current labels: [27.0, 12.0, 16.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 4\n",
      "Thresholds: [np.float64(0.29034894704818726), np.float64(0.004351502957304736), np.float64(0.0026091125328093767), np.float64(0.14676545560359955)]\n",
      "Class labels: [27.0, 12.0, 16.0, 22.0]\n",
      "Current labels: [27.0, 8.0, 12.0, 16.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 5\n",
      "Thresholds: [np.float64(0.11616584380625772), np.float64(0.0012666396796703339), np.float64(0.003574211150407791), np.float64(0.003403609851375222), np.float64(0.1506791114807129)]\n",
      "Class labels: [27.0, 8.0, 12.0, 16.0, 22.0]\n",
      "Current labels: [27.0, 8.0, 9.0, 12.0, 16.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 6\n",
      "Thresholds: [np.float64(0.061989348381757736), np.float64(0.001221268204972148), np.float64(0.0003360891546856388), np.float64(0.003252268536016345), np.float64(0.0029836876783519983), np.float64(0.22582809627056122)]\n",
      "Class labels: [27.0, 8.0, 9.0, 12.0, 16.0, 22.0]\n",
      "Current labels: [27.0, 9.0, 8.0, 12.0, 16.0, 21.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 7\n",
      "Thresholds: [np.float64(0.06446895748376846), np.float64(0.0034203749992412326), np.float64(0.0015409861225634813), np.float64(0.009214020389991605), np.float64(0.0029678307473659515), np.float64(0.12473081052303314), np.float64(0.18273472785949707)]\n",
      "Class labels: [27.0, 9.0, 8.0, 12.0, 16.0, 21.0, 22.0]\n",
      "Current labels: [27.0, 0.0, 9.0, 8.0, 12.0, 16.0, 21.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 8\n",
      "Thresholds: [np.float64(0.13714580237865448), np.float64(0.3544708788394928), np.float64(0.0010287880431860685), np.float64(0.0013524394016712904), np.float64(0.004222038201987743), np.float64(0.0024282995145767927), np.float64(0.27330437302589417), np.float64(0.17012977600097656)]\n",
      "Class labels: [27.0, 0.0, 9.0, 8.0, 12.0, 16.0, 21.0, 22.0]\n",
      "Current labels: [27.0, 0.0, 8.0, 12.0, 9.0, 16.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 9\n",
      "Thresholds: [np.float64(0.05759648233652115), np.float64(0.9581732017083365), np.float64(0.0012034064857289195), np.float64(0.0038934468757361174), np.float64(0.001514496747404337), np.float64(0.007943251405956857), np.float64(0.17555157840251923), np.float64(0.13513872027397156), np.float64(0.1471581757068634)]\n",
      "Class labels: [27.0, 0.0, 8.0, 12.0, 9.0, 16.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 8.0, 9.0, 13.0, 12.0, 16.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.10528066754341125), np.float64(0.13930313289165497), np.float64(0.0010458639590069652), np.float64(0.0011106763267889619), np.float64(0.08697532117366791), np.float64(0.0030887811444699764), np.float64(0.0032916462514549494), np.float64(0.3754929006099701), np.float64(10.902718050598398), np.float64(0.0786885917186737)]\n",
      "Class labels: [27.0, 0.0, 8.0, 9.0, 13.0, 12.0, 16.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 8.0, 0.0, 9.0, 12.0, 15.0, 13.0, 16.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 11\n",
      "Thresholds: [np.float64(0.06652933359146118), np.float64(0.0011025851126760244), np.float64(0.10510434955358505), np.float64(0.004681664390928986), np.float64(0.0032166773453354836), np.float64(0.012597412449940434), np.float64(0.06751996278762817), np.float64(0.010531235530778931), np.float64(0.264910489320755), np.float64(0.2781078517436981), np.float64(0.399324098956388)]\n",
      "Class labels: [27.0, 8.0, 0.0, 9.0, 12.0, 15.0, 13.0, 16.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 9.0, 8.0, 11.0, 12.0, 15.0, 13.0, 16.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 12\n",
      "Thresholds: [np.float64(0.06508691608905792), np.float64(0.11617308109998703), np.float64(0.0016070884885266423), np.float64(0.0014479593373835087), np.float64(0.0011172870872542262), np.float64(0.0035666495095938444), np.float64(0.02335182620353787), np.float64(0.09222743660211563), np.float64(0.00835145639894996), np.float64(0.44176653027534485), np.float64(0.1391141414642334), np.float64(0.601311242283085)]\n",
      "Class labels: [27.0, 0.0, 9.0, 8.0, 11.0, 12.0, 15.0, 13.0, 16.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 8.0, 9.0, 11.0, 0.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 13\n",
      "Thresholds: [np.float64(0.07224331051111221), np.float64(0.0015372816706076264), np.float64(0.0009967891965061426), np.float64(0.0008540319977328181), np.float64(0.1544632762670517), np.float64(0.0039322408847510815), np.float64(0.1166607066988945), np.float64(0.002679659053683281), np.float64(0.009146648879175184), np.float64(0.0030599150341004133), np.float64(0.12430457770824432), np.float64(0.3185482621192932), np.float64(1.372822304472467)]\n",
      "Class labels: [27.0, 8.0, 9.0, 11.0, 0.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 8.0, 9.0, 11.0, 1.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 14\n",
      "Thresholds: [np.float64(0.1325737088918686), np.float64(0.6252652013008015), np.float64(0.0014702931512147188), np.float64(0.0007223048596642911), np.float64(0.0009058513096533716), np.float64(0.1067035123705864), np.float64(0.004985792562365532), np.float64(0.0851992592215538), np.float64(0.0056488356867153595), np.float64(0.005107634887351508), np.float64(0.004213728636433177), np.float64(0.2721407115459442), np.float64(0.21222466230392456), np.float64(0.9561494366357883)]\n",
      "Class labels: [27.0, 0.0, 8.0, 9.0, 11.0, 1.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 1.0, 0.0, 8.0, 9.0, 11.0, 4.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 15\n",
      "Thresholds: [np.float64(0.1786869317293167), np.float64(0.14687976241111755), np.float64(0.3623347580432892), np.float64(0.0014337815809994936), np.float64(0.0011204786133021116), np.float64(0.0008335703751072288), np.float64(0.002902947599068284), np.float64(0.0038257665000855923), np.float64(0.06770552694797516), np.float64(0.002315688878297806), np.float64(0.014262811207496635), np.float64(0.0020142404828220606), np.float64(0.13956089317798615), np.float64(0.25917643308639526), np.float64(0.2879734274255482)]\n",
      "Class labels: [27.0, 1.0, 0.0, 8.0, 9.0, 11.0, 4.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 4.0, 1.0, 8.0, 9.0, 11.0, 5.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 16\n",
      "Thresholds: [np.float64(0.15204910933971405), np.float64(0.3710060119628906), np.float64(0.0028387729544192553), np.float64(0.13030770421028137), np.float64(0.0013166338903829455), np.float64(0.00267802429055705), np.float64(0.0011306601809337735), np.float64(0.014606445096433163), np.float64(0.0033329641446471214), np.float64(0.1136602982878685), np.float64(0.011986315871421217), np.float64(0.0009131863929398229), np.float64(0.002009353134781122), np.float64(0.44319015741348267), np.float64(0.1491745412349701), np.float64(0.4896747611716934)]\n",
      "Class labels: [27.0, 0.0, 4.0, 1.0, 8.0, 9.0, 11.0, 5.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 1.0, 4.0, 2.0, 8.0, 9.0, 11.0, 5.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 17\n",
      "Thresholds: [np.float64(0.1650121510028839), np.float64(1.1264270966461334), np.float64(0.09555339068174362), np.float64(0.0024372595362365246), np.float64(0.04917741941949316), np.float64(0.0013238659594208002), np.float64(0.0016641410766169429), np.float64(0.0009438064298592508), np.float64(0.01792212389409542), np.float64(0.004815826658159494), np.float64(0.12445051223039627), np.float64(0.0029161174315959215), np.float64(0.02418012635271826), np.float64(0.0015256393235176802), np.float64(0.10681427270174026), np.float64(0.2222369760274887), np.float64(1.0468152701850737)]\n",
      "Class labels: [27.0, 0.0, 1.0, 4.0, 2.0, 8.0, 9.0, 11.0, 5.0, 12.0, 13.0, 16.0, 15.0, 17.0, 21.0, 22.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 1.0, 2.0, 5.0, 4.0, 9.0, 11.0, 12.0, 8.0, 13.0, 15.0, 17.0, 16.0, 21.0, 22.0, 24.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 18\n",
      "Thresholds: [np.float64(0.1137666180729866), np.float64(0.19409948587417603), np.float64(0.23412780463695526), np.float64(0.059249069541692734), np.float64(0.017123550176620483), np.float64(0.0027636541053652763), np.float64(0.0012822790304198861), np.float64(0.000914587639272213), np.float64(0.0031864389311522245), np.float64(0.001570551423355937), np.float64(0.05375014990568161), np.float64(0.02237563292935226), np.float64(0.012273595333757985), np.float64(0.0038231404032558203), np.float64(0.141524076461792), np.float64(0.3113081455230713), np.float64(0.08473801612854004), np.float64(0.0763477236032486)]\n",
      "Class labels: [27.0, 0.0, 1.0, 2.0, 5.0, 4.0, 9.0, 11.0, 12.0, 8.0, 13.0, 15.0, 17.0, 16.0, 21.0, 22.0, 24.0, 26.0]\n",
      "Current labels: [27.0, 1.0, 0.0, 2.0, 3.0, 5.0, 4.0, 9.0, 11.0, 12.0, 8.0, 13.0, 15.0, 17.0, 16.0, 21.0, 22.0, 24.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 19\n",
      "Thresholds: [np.float64(0.1510469913482666), np.float64(0.1414436250925064), np.float64(0.12225057929754257), np.float64(0.000767883354596155), np.float64(0.1194629892706871), np.float64(0.013585259715833006), np.float64(0.0025995559990406036), np.float64(0.0008721226477064192), np.float64(0.0011921299155801535), np.float64(0.004926664754748344), np.float64(0.0014217346906661987), np.float64(0.08367794752120972), np.float64(0.008073438050916912), np.float64(0.0012338839005678892), np.float64(0.0022729597985744476), np.float64(0.3742402195930481), np.float64(0.1276582032442093), np.float64(0.07538937032222748), np.float64(1.5774363589998608)]\n",
      "Class labels: [27.0, 1.0, 0.0, 2.0, 3.0, 5.0, 4.0, 9.0, 11.0, 12.0, 8.0, 13.0, 15.0, 17.0, 16.0, 21.0, 22.0, 24.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 2.0, 1.0, 3.0, 4.0, 8.0, 5.0, 11.0, 12.0, 13.0, 9.0, 15.0, 16.0, 21.0, 17.0, 22.0, 23.0, 24.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 20\n",
      "Thresholds: [np.float64(0.06436324119567871), np.float64(0.0997396856546402), np.float64(0.1902484893798828), np.float64(0.20215007662773132), np.float64(0.12586413323879242), np.float64(0.0029207230545580387), np.float64(0.0018958813743665814), np.float64(0.014188173227012157), np.float64(0.010419570584905589), np.float64(0.003934784326702356), np.float64(0.05112280324101448), np.float64(0.0006774643552489579), np.float64(0.016873862986228793), np.float64(0.013327539047238803), np.float64(0.18945853412151337), np.float64(0.003917579045043047), np.float64(0.1512841135263443), np.float64(0.6843487566094285), np.float64(0.10565058141946793), np.float64(0.3242552578449249)]\n",
      "Class labels: [27.0, 0.0, 2.0, 1.0, 3.0, 4.0, 8.0, 5.0, 11.0, 12.0, 13.0, 9.0, 15.0, 16.0, 21.0, 17.0, 22.0, 23.0, 24.0, 26.0]\n",
      "Current labels: [27.0, 1.0, 2.0, 3.0, 0.0, 4.0, 5.0, 9.0, 8.0, 12.0, 13.0, 15.0, 11.0, 16.0, 17.0, 22.0, 21.0, 23.0, 24.0, 25.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 21\n",
      "Thresholds: [np.float64(0.2559882700443268), np.float64(0.1838243007659912), np.float64(0.3034981572040837), np.float64(0.08003858476877213), np.float64(0.1137218102812767), np.float64(0.0028375338297337294), np.float64(0.006097152010432143), np.float64(0.0024054083017315837), np.float64(0.0014559451956301928), np.float64(0.004927216563373804), np.float64(0.06389077752828598), np.float64(0.019972456309406427), np.float64(0.001095719519071281), np.float64(0.0026409931015223265), np.float64(0.00030063804262358065), np.float64(0.2144017368555069), np.float64(0.18933428823947906), np.float64(0.0660366639494896), np.float64(0.08415563404560089), np.float64(0.11162352600941239), np.float64(0.84231230798545)]\n",
      "Class labels: [27.0, 1.0, 2.0, 3.0, 0.0, 4.0, 5.0, 9.0, 8.0, 12.0, 13.0, 15.0, 11.0, 16.0, 17.0, 22.0, 21.0, 23.0, 24.0, 25.0, 26.0]\n",
      "Current labels: [27.0, 0.0, 2.0, 3.0, 4.0, 1.0, 5.0, 8.0, 11.0, 9.0, 13.0, 15.0, 16.0, 12.0, 17.0, 18.0, 22.0, 21.0, 23.0, 24.0, 25.0, 26.0]\n",
      "*** Update model ***\n",
      "Number of models: 22\n",
      "Thresholds: [np.float64(0.07163678854703903), np.float64(0.5880188789803547), np.float64(0.06589437276124954), np.float64(0.19080664217472076), np.float64(0.0031619358342140913), np.float64(0.14072075486183167), np.float64(0.013662018813192844), np.float64(0.0009181538480333984), np.float64(0.0008844506810419261), np.float64(0.0010383334010839462), np.float64(0.09748093783855438), np.float64(0.013633020296282449), np.float64(0.005112123801745451), np.float64(0.003572080284357071), np.float64(0.006134421712042457), np.float64(0.06458505243062973), np.float64(0.305253267288208), np.float64(0.22600410878658295), np.float64(0.3621146958504833), np.float64(0.13346706330776215), np.float64(0.035265300422906876), np.float64(0.33869962893327277)]\n",
      "Class labels: [27.0, 0.0, 2.0, 3.0, 4.0, 1.0, 5.0, 8.0, 11.0, 9.0, 13.0, 15.0, 16.0, 12.0, 17.0, 18.0, 22.0, 21.0, 23.0, 24.0, 25.0, 26.0]\n",
      "Current labels: [27.0, 1.0, 0.0, 3.0, 4.0, 5.0, 2.0, 8.0, 9.0, 12.0, 11.0, 15.0, 16.0, 17.0, 13.0, 18.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "*** Update model ***\n",
      "Number of models: 23\n",
      "Thresholds: [np.float64(0.07472661137580872), np.float64(0.1053345381632933), np.float64(5.0713504708083414), np.float64(0.06360382046600188), np.float64(0.002764434088021517), np.float64(0.015328517183661461), np.float64(0.0640080261806106), np.float64(0.0013720507267862558), np.float64(0.003326124752221339), np.float64(0.0033917815890163183), np.float64(0.0013273385120555758), np.float64(0.009128846590944949), np.float64(0.002714786445721984), np.float64(0.0048277885664475655), np.float64(0.06077812984585762), np.float64(0.0582096092402935), np.float64(0.2217285931110382), np.float64(0.05278969556093216), np.float64(0.16602224111557007), np.float64(0.072921983897686), np.float64(0.0006154968708012576), np.float64(0.23304630815982819), np.float64(0.10292866080999374)]\n",
      "Class labels: [27.0, 1.0, 0.0, 3.0, 4.0, 5.0, 2.0, 8.0, 9.0, 12.0, 11.0, 15.0, 16.0, 17.0, 13.0, 18.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "Current labels: [27.0, 0.0, 2.0, 1.0, 4.0, 5.0, 8.0, 3.0, 9.0, 11.0, 13.0, 12.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "*** Update model ***\n",
      "Number of models: 24\n",
      "Thresholds: [np.float64(0.27844369411468506), np.float64(0.15321290493011475), np.float64(0.14873653650283813), np.float64(0.1474919617176056), np.float64(0.0028499497566372156), np.float64(0.021469306983938063), np.float64(0.0011154075618833303), np.float64(0.1507352590560913), np.float64(0.0010942767839878798), np.float64(0.0013429904356598854), np.float64(0.11719286441802979), np.float64(0.003732315730303526), np.float64(0.003967861076002447), np.float64(0.0028928485591431727), np.float64(0.14363911747932434), np.float64(0.01048408301331866), np.float64(0.001682094261383573), np.float64(0.09751845896244049), np.float64(0.07980218529701233), np.float64(0.12934742867946625), np.float64(0.09163619577884674), np.float64(0.024956819226576443), np.float64(0.6270969508443912), np.float64(2.9168243023134273)]\n",
      "Class labels: [27.0, 0.0, 2.0, 1.0, 4.0, 5.0, 8.0, 3.0, 9.0, 11.0, 13.0, 12.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "Current labels: [27.0, 1.0, 2.0, 3.0, 4.0, 5.0, 7.0, 8.0, 0.0, 9.0, 11.0, 13.0, 12.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "*** Update model ***\n",
      "Number of models: 25\n",
      "Thresholds: [np.float64(0.054833754897117615), np.float64(0.1245664432644844), np.float64(0.05327858030796051), np.float64(0.10956735908985138), np.float64(0.002552182413637638), np.float64(0.016175968572497368), np.float64(0.047622965070689895), np.float64(0.001467548543587327), np.float64(0.22160114347934723), np.float64(0.0008895608480088413), np.float64(0.001050458406098187), np.float64(0.09188589453697205), np.float64(0.01060504393862563), np.float64(0.002253894694149494), np.float64(0.0012936407001689076), np.float64(0.07483337819576263), np.float64(0.011079174900482963), np.float64(0.034402802547133585), np.float64(0.14860418438911438), np.float64(0.8804064215780021), np.float64(0.18478131294250488), np.float64(0.094533272087574), np.float64(0.061163280159235), np.float64(0.1361343413591385), np.float64(0.11576317250728607)]\n",
      "Class labels: [27.0, 1.0, 2.0, 3.0, 4.0, 5.0, 7.0, 8.0, 0.0, 9.0, 11.0, 13.0, 12.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "Current labels: [27.0, 0.0, 2.0, 3.0, 4.0, 5.0, 7.0, 8.0, 9.0, 1.0, 10.0, 11.0, 13.0, 12.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "*** Update model ***\n",
      "Number of models: 26\n",
      "Thresholds: [np.float64(0.08527464419603348), np.float64(0.21219711005687714), np.float64(0.0651501789689064), np.float64(0.36309632658958435), np.float64(0.003518554614856839), np.float64(0.01542346179485321), np.float64(0.005946692544966936), np.float64(0.0011589113855734468), np.float64(0.0009052261593751609), np.float64(0.20233722031116486), np.float64(0.01888391375541687), np.float64(0.0009413442458026111), np.float64(0.07387921959161758), np.float64(0.0029210348147898912), np.float64(0.003566873027011752), np.float64(0.0013845745706930757), np.float64(0.0546865351498127), np.float64(0.016687376260402904), np.float64(0.0020986406598240137), np.float64(0.28687623143196106), np.float64(0.062068406492471695), np.float64(0.43936997652053833), np.float64(0.11858529597520828), np.float64(0.09953141546220523), np.float64(0.005072816147768666), np.float64(1.463563757379943)]\n",
      "Class labels: [27.0, 0.0, 2.0, 3.0, 4.0, 5.0, 7.0, 8.0, 9.0, 1.0, 10.0, 11.0, 13.0, 12.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "Current labels: [27.0, 1.0, 0.0, 3.0, 4.0, 5.0, 7.0, 8.0, 9.0, 10.0, 2.0, 11.0, 12.0, 14.0, 13.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "*** Update model ***\n",
      "Number of models: 27\n",
      "Thresholds: [np.float64(0.055290333926677704), np.float64(0.15627901256084442), np.float64(0.20992015302181244), np.float64(0.30249375343811535), np.float64(0.0037853331305086613), np.float64(0.014687995426356792), np.float64(0.04541707760118316), np.float64(0.0008881816174834967), np.float64(0.0008115494274534285), np.float64(0.037502104348471045), np.float64(0.057123031467199326), np.float64(0.0006779839168302715), np.float64(0.0044188061729073524), np.float64(0.2734983265399933), np.float64(0.10021854192018509), np.float64(0.0022371301893144846), np.float64(0.0011636996641755104), np.float64(0.045679591596126556), np.float64(0.011697355596230849), np.float64(0.0016462779603898525), np.float64(0.24318775534629822), np.float64(0.09067718940648772), np.float64(0.11608204245567322), np.float64(0.09264294058084488), np.float64(0.1290526338523549), np.float64(0.741878763746189), np.float64(0.12474679946899414)]\n",
      "Class labels: [27.0, 1.0, 0.0, 3.0, 4.0, 5.0, 7.0, 8.0, 9.0, 10.0, 2.0, 11.0, 12.0, 14.0, 13.0, 16.0, 17.0, 18.0, 15.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "Current labels: [27.0, 0.0, 2.0, 1.0, 4.0, 5.0, 7.0, 8.0, 9.0, 10.0, 11.0, 3.0, 12.0, 13.0, 15.0, 14.0, 17.0, 18.0, 19.0, 16.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "*** Update model ***\n",
      "Number of models: 28\n",
      "Thresholds: [np.float64(0.2940947413444519), np.float64(0.17417874932289124), np.float64(0.11888716196256077), np.float64(0.10160703957080841), np.float64(0.002697621937841177), np.float64(0.015304823406040668), np.float64(0.055934718511450834), np.float64(0.001585710677318275), np.float64(0.003737532517238632), np.float64(0.029007866702050356), np.float64(0.001029229606501758), np.float64(0.08984207361936569), np.float64(0.0036948330234736204), np.float64(0.07579585164785385), np.float64(0.018723828341572796), np.float64(0.35713081490121124), np.float64(0.0015197318280115724), np.float64(0.04955550283193588), np.float64(0.0016032380517572165), np.float64(0.0013878958106485172), np.float64(0.04036176948713966), np.float64(0.1350339949131012), np.float64(0.01437435942050913), np.float64(0.7879279255867004), np.float64(0.3229289948940277), np.float64(0.030336062009465953), np.float64(0.09638451784849167), np.float64(0.10810402035713196)]\n",
      "Class labels: [27.0, 0.0, 2.0, 1.0, 4.0, 5.0, 7.0, 8.0, 9.0, 10.0, 11.0, 3.0, 12.0, 13.0, 15.0, 14.0, 17.0, 18.0, 19.0, 16.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "\n",
      "Number of models: 28\n",
      "Thresholds: [np.float64(0.2940947413444519), np.float64(0.17417874932289124), np.float64(0.11888716196256077), np.float64(0.10160703957080841), np.float64(0.002697621937841177), np.float64(0.015304823406040668), np.float64(0.055934718511450834), np.float64(0.001585710677318275), np.float64(0.003737532517238632), np.float64(0.029007866702050356), np.float64(0.001029229606501758), np.float64(0.08984207361936569), np.float64(0.0036948330234736204), np.float64(0.07579585164785385), np.float64(0.018723828341572796), np.float64(0.35713081490121124), np.float64(0.0015197318280115724), np.float64(0.04955550283193588), np.float64(0.0016032380517572165), np.float64(0.0013878958106485172), np.float64(0.04036176948713966), np.float64(0.1350339949131012), np.float64(0.01437435942050913), np.float64(0.7879279255867004), np.float64(0.3229289948940277), np.float64(0.030336062009465953), np.float64(0.09638451784849167), np.float64(0.10810402035713196)]\n",
      "Class labels: [27.0, 0.0, 2.0, 1.0, 4.0, 5.0, 7.0, 8.0, 9.0, 10.0, 11.0, 3.0, 12.0, 13.0, 15.0, 14.0, 17.0, 18.0, 19.0, 16.0, 20.0, 21.0, 23.0, 22.0, 24.0, 25.0, 26.0, 28.0]\n",
      "=== Prediction Results ===\n",
      "res_ls contents: [999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 27.0, 999, 27.0, 999, 27.0, 999, 27.0, 999, 999, 27.0, 27.0, 999, 27.0, 27.0, 999, 27.0, 999, 999, 27.0, 999, 27.0, 999, 27.0, 27.0, 999, 27.0, 999, 999, 27.0, 999, 27.0, 999, 27.0, 999, 999, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 999, 27.0, 27.0, 999, 27.0, 999, 27.0, 999, 27.0, 999, 27.0, 999, 999, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 27.0, 27.0, 999, 999, 999, 999, 999, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 999, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 999, 999, 27.0, 999, 27.0, 999, 999, 27.0, 999, 999, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 27.0, 27.0, 999, 999, 999, 27.0, 999, 999, 27.0, 27.0, 27.0, 27.0, 999, 999, 27.0, 999, 27.0, 999, 999, 27.0, 999, 999, 999, 999, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 999, 999, 999, 999, 27.0, 999, 27.0, 999, 999, 27.0, 999, 999, 999, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 999, 27.0, 999, 27.0, 27.0, 999, 999, 27.0, 999, 27.0, 999, 999, 27.0, 999, 999, 27.0, 999, 999, 999, 27.0, 27.0, 999, 27.0, 999, 999, 27.0, 999, 999, 27.0, 999, 999, 999, 999, 27.0, 999, 27.0, 27.0, 999, 27.0, 999, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 27.0, 27.0, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 27.0, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 27.0, 22.0, 27.0, 22.0, 22.0, 22.0, 22.0, 999, 27.0, 22.0, 999, 27.0, 999, 22.0, 22.0, 999, 27.0, 27.0, 999, 22.0, 27.0, 27.0, 22.0, 27.0, 22.0, 22.0, 22.0, 27.0, 22.0, 22.0, 27.0, 27.0, 27.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 22.0, 27.0, 22.0, 22.0, 27.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 22.0, 22.0, 999, 27.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 22.0, 27.0, 22.0, 27.0, 22.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 22.0, 22.0, 27.0, 22.0, 22.0, 22.0, 999, 22.0, 27.0, 27.0, 22.0, 999, 999, 22.0, 999, 27.0, 22.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 22.0, 22.0, 27.0, 22.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 999, 999, 22.0, 27.0, 22.0, 999, 22.0, 22.0, 22.0, 999, 999, 999, 22.0, 999, 22.0, 27.0, 22.0, 22.0, 22.0, 22.0, 22.0, 27.0, 22.0, 22.0, 22.0, 22.0, 27.0, 22.0, 22.0, 27.0, 22.0, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 22.0, 27.0, 999, 22.0, 27.0, 27.0, 22.0, 27.0, 22.0, 27.0, 27.0, 27.0, 22.0, 22.0, 27.0, 22.0, 27.0, 22.0, 999, 22.0, 27.0, 22.0, 22.0, 27.0, 27.0, 22.0, 22.0, 22.0, 27.0, 999, 27.0, 22.0, 27.0, 999, 22.0, 27.0, 22.0, 22.0, 27.0, 27.0, 22.0, 22.0, 27.0, 22.0, 27.0, 999, 27.0, 22.0, 27.0, 999, 22.0, 27.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 999, 27.0, 22.0, 27.0, 22.0, 27.0, 27.0, 22.0, 22.0, 999, 22.0, 27.0, 27.0, 22.0, 22.0, 27.0, 22.0, 999, 22.0, 27.0, 27.0, 22.0, 22.0, 22.0, 999, 999, 27.0, 22.0, 999, 22.0, 22.0, 22.0, 27.0, 22.0, 27.0, 21.0, 999, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 27.0, 27.0, 999, 27.0, 999, 27.0, 27.0, 21.0, 27.0, 27.0, 27.0, 21.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 27.0, 21.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 999, 22.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 21.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 21.0, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 21.0, 27.0, 22.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 21.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 999, 999, 27.0, 22.0, 27.0, 27.0, 27.0, 22.0, 22.0, 999, 27.0, 27.0, 27.0, 21.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 21.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 999, 27.0, 27.0, 27.0, 999, 27.0, 21.0, 999, 22.0, 27.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 999, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 999, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 22.0, 27.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 22.0, 999, 27.0, 27.0, 27.0, 27.0, 22.0, 999, 999, 999, 999, 27.0, 999, 27.0, 27.0, 999, 27.0, 21.0, 21.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 22.0, 999, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 22.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 21.0, 999, 27.0, 0.0, 999, 27.0, 999, 27.0, 21.0, 27.0, 22.0, 0.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 21.0, 999, 27.0, 27.0, 0.0, 27.0, 27.0, 22.0, 22.0, 27.0, 27.0, 21.0, 27.0, 27.0, 27.0, 22.0, 999, 27.0, 22.0, 21.0, 999, 27.0, 27.0, 0.0, 0.0, 27.0, 27.0, 27.0, 21.0, 999, 27.0, 21.0, 27.0, 27.0, 999, 22.0, 0.0, 27.0, 21.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 21.0, 27.0, 0.0, 27.0, 27.0, 0.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 22.0, 27.0, 22.0, 22.0, 27.0, 27.0, 27.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 999, 27.0, 22.0, 21.0, 0.0, 22.0, 27.0, 27.0, 21.0, 27.0, 27.0, 27.0, 21.0, 27.0, 0.0, 999, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 999, 22.0, 27.0, 27.0, 27.0, 0.0, 22.0, 27.0, 27.0, 27.0, 27.0, 0.0, 21.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 0.0, 0.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 21.0, 27.0, 999, 27.0, 27.0, 22.0, 22.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 21.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 999, 999, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 999, 27.0, 22.0, 27.0, 27.0, 999, 27.0, 22.0, 22.0, 27.0, 22.0, 27.0, 0.0, 27.0, 0.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 999, 0.0, 0.0, 22.0, 999, 27.0, 27.0, 999, 0.0, 0.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 0.0, 0.0, 999, 27.0, 27.0, 0.0, 27.0, 999, 27.0, 0.0, 27.0, 27.0, 26.0, 27.0, 27.0, 27.0, 22.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 26.0, 27.0, 27.0, 27.0, 26.0, 0.0, 26.0, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 22.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 999, 0.0, 27.0, 0.0, 27.0, 0.0, 27.0, 27.0, 27.0, 0.0, 26.0, 0.0, 27.0, 0.0, 27.0, 26.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 26.0, 27.0, 0.0, 27.0, 27.0, 26.0, 999, 27.0, 0.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 0.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 999, 27.0, 27.0, 22.0, 27.0, 27.0, 0.0, 27.0, 27.0, 22.0, 27.0, 0.0, 26.0, 0.0, 0.0, 0.0, 27.0, 27.0, 0.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 0.0, 0.0, 27.0, 27.0, 27.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 0.0, 22.0, 22.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 27.0, 27.0, 999, 0.0, 27.0, 27.0, 27.0, 0.0, 999, 999, 27.0, 27.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 27.0, 27.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 0.0, 22.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 0.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 22.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 22.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 22.0, 26.0, 22.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 22.0, 26.0, 26.0, 22.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 22.0, 26.0, 26.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 21.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 999, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 21.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 15.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 21.0, 999, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 26.0, 21.0, 27.0, 999, 27.0, 999, 13.0, 27.0, 21.0, 27.0, 26.0, 0.0, 0.0, 13.0, 27.0, 21.0, 999, 22.0, 22.0, 27.0, 27.0, 27.0, 21.0, 27.0, 26.0, 22.0, 0.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 26.0, 0.0, 27.0, 13.0, 26.0, 27.0, 26.0, 27.0, 27.0, 0.0, 13.0, 27.0, 27.0, 27.0, 27.0, 21.0, 27.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 27.0, 13.0, 27.0, 999, 27.0, 26.0, 27.0, 13.0, 27.0, 27.0, 27.0, 27.0, 26.0, 27.0, 999, 27.0, 21.0, 22.0, 26.0, 22.0, 26.0, 22.0, 21.0, 13.0, 13.0, 27.0, 27.0, 27.0, 26.0, 27.0, 13.0, 26.0, 13.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 27.0, 26.0, 26.0, 0.0, 27.0, 27.0, 27.0, 27.0, 27.0, 999, 13.0, 999, 26.0, 26.0, 27.0, 26.0, 999, 22.0, 27.0, 999, 27.0, 27.0, 999, 26.0, 21.0, 26.0, 27.0, 27.0, 22.0, 26.0, 27.0, 27.0, 999, 27.0, 26.0, 0.0, 21.0, 27.0, 27.0, 27.0, 26.0, 26.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 0.0, 13.0, 27.0, 999, 26.0, 27.0, 999, 26.0, 0.0, 27.0, 26.0, 27.0, 27.0, 13.0, 27.0, 26.0, 27.0, 13.0, 27.0, 26.0, 27.0, 27.0, 27.0, 27.0, 22.0, 27.0, 27.0, 27.0, 27.0, 26.0, 27.0, 26.0, 26.0, 27.0, 27.0, 27.0, 26.0, 26.0, 27.0, 27.0, 26.0, 13.0, 27.0, 0.0, 26.0, 27.0, 999, 27.0, 13.0, 26.0, 27.0, 27.0, 27.0, 27.0, 26.0, 0.0, 27.0, 27.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 13.0, 27.0, 27.0, 26.0, 26.0, 13.0, 13.0, 21.0, 26.0, 26.0, 26.0, 13.0, 27.0, 13.0, 27.0, 27.0, 21.0, 27.0, 26.0, 27.0, 999, 26.0, 27.0, 27.0, 27.0, 26.0, 27.0, 27.0, 26.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 0.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 0.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 999, 15.0, 15.0, 15.0, 15.0, 999, 15.0, 999, 999, 15.0, 15.0, 15.0, 15.0, 999, 15.0, 999, 999, 999, 22.0, 15.0, 15.0, 15.0, 999, 999, 999, 999, 999, 999, 15.0, 999, 15.0, 999, 15.0, 999, 15.0, 999, 999, 999, 15.0, 15.0, 999, 999, 999, 15.0, 15.0, 15.0, 15.0, 999, 15.0, 999, 999, 999, 15.0, 999, 999, 999, 15.0, 999, 999, 999, 15.0, 999, 999, 0.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 999, 15.0, 999, 999, 999, 999, 999, 999, 999, 999, 26.0, 15.0, 999, 15.0, 15.0, 999, 999, 999, 999, 999, 15.0, 999, 15.0, 999, 999, 15.0, 999, 999, 15.0, 999, 15.0, 999, 999, 999, 15.0, 999, 999, 15.0, 999, 999, 15.0, 15.0, 15.0, 999, 999, 0.0, 999, 15.0, 999, 15.0, 15.0, 999, 15.0, 15.0, 999, 999, 999, 15.0, 15.0, 999, 999, 15.0, 999, 15.0, 15.0, 999, 999, 15.0, 999, 15.0, 15.0, 999, 999, 999, 999, 15.0, 999, 999, 15.0, 15.0, 15.0, 15.0, 15.0, 999, 999, 999, 999, 15.0, 15.0, 15.0, 999, 15.0, 15.0, 15.0, 999, 15.0, 999, 999, 15.0, 15.0, 999, 999, 999, 999, 15.0, 15.0, 999, 999, 999, 999, 15.0, 999, 999, 15.0, 15.0, 15.0, 15.0, 999, 15.0, 15.0, 999, 999, 15.0, 999, 15.0, 999, 999, 15.0, 999, 999, 999, 999, 999, 15.0, 999, 0.0, 999, 15.0, 999, 15.0, 999, 15.0, 999, 15.0, 15.0, 15.0, 999, 15.0, 999, 15.0, 15.0, 15.0, 999, 15.0, 15.0, 999, 999, 15.0, 999, 15.0, 999, 15.0, 15.0, 999, 15.0, 999, 15.0, 15.0, 15.0, 15.0, 26.0, 999, 15.0, 999, 15.0, 15.0, 999, 999, 15.0, 15.0, 15.0, 15.0, 15.0, 999, 999, 15.0, 13.0, 26.0, 999, 999, 13.0, 26.0, 13.0, 1.0, 26.0, 26.0, 13.0, 26.0, 1.0, 999, 1.0, 13.0, 26.0, 13.0, 13.0, 13.0, 13.0, 27.0, 13.0, 26.0, 1.0, 26.0, 26.0, 26.0, 26.0, 27.0, 13.0, 27.0, 26.0, 26.0, 27.0, 999, 26.0, 26.0, 26.0, 999, 999, 26.0, 13.0, 26.0, 26.0, 26.0, 1.0, 26.0, 26.0, 999, 27.0, 26.0, 999, 999, 26.0, 999, 22.0, 13.0, 26.0, 1.0, 22.0, 26.0, 26.0, 13.0, 26.0, 26.0, 26.0, 999, 27.0, 26.0, 26.0, 26.0, 13.0, 999, 13.0, 999, 22.0, 26.0, 13.0, 999, 1.0, 13.0, 26.0, 27.0, 27.0, 26.0, 999, 27.0, 22.0, 22.0, 13.0, 1.0, 0.0, 1.0, 26.0, 26.0, 13.0, 26.0, 26.0, 26.0, 13.0, 0.0, 26.0, 26.0, 13.0, 26.0, 1.0, 26.0, 27.0, 1.0, 26.0, 26.0, 26.0, 1.0, 22.0, 999, 27.0, 0.0, 999, 26.0, 13.0, 27.0, 999, 27.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 13.0, 999, 26.0, 26.0, 999, 27.0, 999, 26.0, 1.0, 26.0, 26.0, 0.0, 26.0, 26.0, 26.0, 26.0, 13.0, 13.0, 999, 26.0, 26.0, 22.0, 27.0, 13.0, 26.0, 13.0, 22.0, 0.0, 999, 26.0, 22.0, 21.0, 13.0, 26.0, 27.0, 26.0, 22.0, 1.0, 999, 22.0, 13.0, 26.0, 1.0, 26.0, 26.0, 26.0, 999, 26.0, 27.0, 26.0, 22.0, 26.0, 999, 27.0, 999, 13.0, 13.0, 1.0, 999, 26.0, 26.0, 13.0, 0.0, 26.0, 27.0, 22.0, 1.0, 26.0, 13.0, 13.0, 26.0, 26.0, 27.0, 26.0, 13.0, 999, 13.0, 26.0, 22.0, 26.0, 13.0, 26.0, 26.0, 13.0, 13.0, 26.0, 26.0, 27.0, 13.0, 999, 999, 26.0, 27.0, 1.0, 13.0, 22.0, 13.0, 26.0, 999, 13.0, 1.0, 26.0, 22.0, 1.0, 21.0, 999, 22.0, 13.0, 13.0, 26.0, 21.0, 27.0, 26.0, 26.0, 26.0, 999, 22.0, 999, 27.0, 13.0, 13.0, 999, 999, 27.0, 26.0, 27.0, 26.0, 26.0, 26.0, 1.0, 2.0, 1.0, 21.0, 26.0, 26.0, 26.0, 22.0, 26.0, 21.0, 26.0, 1.0, 22.0, 26.0, 26.0, 26.0, 26.0, 27.0, 1.0, 999, 21.0, 22.0, 26.0, 26.0, 999, 22.0, 22.0, 999, 22.0, 26.0, 22.0, 21.0, 26.0, 26.0, 26.0, 1.0, 26.0, 27.0, 1.0, 1.0, 22.0, 21.0, 26.0, 22.0, 22.0, 26.0, 26.0, 26.0, 22.0, 1.0, 27.0, 2.0, 1.0, 26.0, 22.0, 21.0, 26.0, 1.0, 1.0, 26.0, 27.0, 27.0, 26.0, 21.0, 22.0, 26.0, 22.0, 21.0, 26.0, 26.0, 22.0, 26.0, 22.0, 26.0, 22.0, 13.0, 22.0, 13.0, 26.0, 22.0, 22.0, 26.0, 21.0, 26.0, 26.0, 27.0, 1.0, 26.0, 22.0, 26.0, 22.0, 13.0, 21.0, 22.0, 22.0, 2.0, 26.0, 26.0, 26.0, 22.0, 26.0, 26.0, 26.0, 22.0, 1.0, 22.0, 22.0, 22.0, 1.0, 21.0, 1.0, 1.0, 26.0, 21.0, 1.0, 21.0, 21.0, 22.0, 13.0, 22.0, 21.0, 22.0, 26.0, 26.0, 22.0, 26.0, 26.0, 2.0, 26.0, 22.0, 1.0, 22.0, 21.0, 22.0, 27.0, 21.0, 13.0, 21.0, 26.0, 26.0, 26.0, 26.0, 13.0, 26.0, 26.0, 1.0, 26.0, 26.0, 22.0, 26.0, 22.0, 22.0, 21.0, 21.0, 2.0, 26.0, 22.0, 1.0, 1.0, 22.0, 22.0, 21.0, 26.0, 22.0, 1.0, 22.0, 26.0, 26.0, 21.0, 22.0, 22.0, 999, 26.0, 21.0, 22.0, 1.0, 26.0, 999, 22.0, 1.0, 22.0, 26.0, 13.0, 21.0, 21.0, 26.0, 22.0, 1.0, 13.0, 26.0, 1.0, 21.0, 1.0, 1.0, 22.0, 2.0, 26.0, 1.0, 1.0, 999, 22.0, 22.0, 999, 22.0, 22.0, 26.0, 22.0, 26.0, 22.0, 22.0, 1.0, 26.0, 27.0, 1.0, 1.0, 21.0, 1.0, 26.0, 21.0, 26.0, 21.0, 1.0, 999, 26.0, 1.0, 2.0, 22.0, 27.0, 13.0, 26.0, 1.0, 1.0, 21.0, 22.0, 26.0, 22.0, 21.0, 22.0, 1.0, 21.0, 21.0, 21.0, 22.0, 21.0, 26.0, 22.0, 22.0, 21.0, 22.0, 21.0, 26.0, 26.0, 27.0, 13.0, 21.0, 26.0, 26.0, 1.0, 1.0, 1.0, 21.0, 26.0, 2.0, 26.0, 2.0, 2.0, 24.0, 26.0, 999, 2.0, 13.0, 2.0, 999, 0.0, 13.0, 999, 13.0, 999, 999, 999, 26.0, 2.0, 13.0, 999, 999, 999, 2.0, 26.0, 24.0, 2.0, 999, 13.0, 2.0, 999, 26.0, 2.0, 1.0, 1.0, 24.0, 2.0, 2.0, 999, 13.0, 26.0, 2.0, 27.0, 2.0, 1.0, 2.0, 999, 26.0, 2.0, 2.0, 26.0, 2.0, 999, 2.0, 2.0, 26.0, 2.0, 26.0, 2.0, 2.0, 2.0, 13.0, 26.0, 999, 26.0, 2.0, 2.0, 26.0, 13.0, 2.0, 26.0, 26.0, 999, 999, 26.0, 2.0, 2.0, 26.0, 2.0, 2.0, 999, 2.0, 2.0, 1.0, 2.0, 999, 13.0, 2.0, 26.0, 0.0, 26.0, 0.0, 999, 26.0, 26.0, 13.0, 999, 26.0, 2.0, 999, 2.0, 2.0, 13.0, 999, 24.0, 999, 13.0, 26.0, 999, 999, 13.0, 2.0, 2.0, 13.0, 13.0, 2.0, 13.0, 0.0, 999, 2.0, 999, 2.0, 13.0, 999, 26.0, 2.0, 2.0, 2.0, 26.0, 13.0, 2.0, 13.0, 999, 999, 2.0, 2.0, 999, 2.0, 2.0, 26.0, 2.0, 1.0, 2.0, 26.0, 2.0, 2.0, 26.0, 999, 2.0, 2.0, 24.0, 999, 26.0, 0.0, 0.0, 999, 2.0, 2.0, 1.0, 13.0, 26.0, 2.0, 2.0, 2.0, 2.0, 2.0, 13.0, 26.0, 999, 13.0, 999, 26.0, 24.0, 2.0, 2.0, 13.0, 999, 0.0, 2.0, 1.0, 2.0, 2.0, 13.0, 26.0, 26.0, 26.0, 999, 26.0, 2.0, 2.0, 13.0, 0.0, 999, 2.0, 2.0, 2.0, 24.0, 2.0, 999, 2.0, 2.0, 2.0, 1.0, 13.0, 2.0, 26.0, 999, 13.0, 2.0, 2.0, 999, 999, 24.0, 2.0, 2.0, 999, 999, 999, 24.0, 999, 13.0, 1.0, 13.0, 2.0, 26.0, 26.0, 1.0, 2.0, 999, 24.0, 2.0, 999, 26.0, 26.0, 27.0, 999, 999, 999, 2.0, 13.0, 13.0, 13.0, 0.0, 26.0, 13.0, 2.0, 2.0, 13.0, 2.0, 2.0, 999, 2.0, 999, 13.0, 2.0, 26.0, 26.0, 999, 22.0, 24.0, 27.0, 24.0, 1.0, 1.0, 24.0, 24.0, 1.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 24.0, 24.0, 26.0, 13.0, 26.0, 24.0, 26.0, 24.0, 24.0, 3.0, 24.0, 13.0, 22.0, 22.0, 13.0, 0.0, 0.0, 26.0, 22.0, 24.0, 24.0, 26.0, 1.0, 24.0, 24.0, 26.0, 24.0, 13.0, 24.0, 24.0, 24.0, 24.0, 24.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 3.0, 24.0, 22.0, 3.0, 1.0, 24.0, 999, 26.0, 1.0, 24.0, 3.0, 26.0, 26.0, 13.0, 22.0, 24.0, 24.0, 22.0, 1.0, 24.0, 13.0, 24.0, 1.0, 1.0, 3.0, 22.0, 13.0, 13.0, 13.0, 24.0, 26.0, 24.0, 22.0, 24.0, 24.0, 24.0, 0.0, 26.0, 24.0, 13.0, 26.0, 27.0, 24.0, 1.0, 24.0, 24.0, 3.0, 24.0, 24.0, 1.0, 26.0, 24.0, 1.0, 24.0, 26.0, 24.0, 26.0, 26.0, 24.0, 24.0, 24.0, 1.0, 0.0, 24.0, 24.0, 24.0, 3.0, 24.0, 24.0, 24.0, 27.0, 24.0, 3.0, 24.0, 22.0, 0.0, 24.0, 22.0, 1.0, 13.0, 1.0, 26.0, 1.0, 26.0, 26.0, 24.0, 26.0, 26.0, 26.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 26.0, 24.0, 24.0, 22.0, 24.0, 24.0, 22.0, 24.0, 26.0, 24.0, 13.0, 26.0, 13.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 26.0, 24.0, 0.0, 24.0, 24.0, 24.0, 27.0, 13.0, 22.0, 24.0, 26.0, 26.0, 24.0, 26.0, 24.0, 24.0, 0.0, 24.0, 13.0, 24.0, 24.0, 26.0, 3.0, 24.0, 22.0, 13.0, 24.0, 26.0, 1.0, 1.0, 26.0, 26.0, 24.0, 999, 26.0, 13.0, 24.0, 24.0, 26.0, 26.0, 3.0, 26.0, 26.0, 26.0, 1.0, 24.0, 26.0, 0.0, 13.0, 26.0, 3.0, 0.0, 24.0, 26.0, 22.0, 24.0, 24.0, 24.0, 22.0, 26.0, 24.0, 24.0, 24.0, 26.0, 3.0, 13.0, 0.0, 26.0, 24.0, 24.0, 24.0, 24.0, 26.0, 22.0, 24.0, 1.0, 26.0, 24.0, 22.0, 24.0, 26.0, 13.0, 24.0, 1.0, 24.0, 999, 27.0, 27.0, 27.0, 27.0, 999, 27.0, 23.0, 27.0, 23.0, 23.0, 23.0, 27.0, 27.0, 27.0, 23.0, 13.0, 27.0, 23.0, 27.0, 27.0, 27.0, 0.0, 23.0, 27.0, 27.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 0.0, 13.0, 23.0, 23.0, 23.0, 27.0, 27.0, 13.0, 27.0, 23.0, 13.0, 27.0, 27.0, 27.0, 13.0, 23.0, 27.0, 23.0, 27.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 23.0, 27.0, 23.0, 23.0, 27.0, 27.0, 23.0, 27.0, 23.0, 23.0, 27.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 1.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 27.0, 0.0, 23.0, 27.0, 13.0, 27.0, 27.0, 23.0, 27.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 999, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 23.0, 24.0, 27.0, 27.0, 27.0, 27.0, 23.0, 27.0, 27.0, 13.0, 0.0, 27.0, 13.0, 27.0, 23.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 2.0, 27.0, 0.0, 27.0, 23.0, 999, 27.0, 27.0, 23.0, 27.0, 23.0, 27.0, 27.0, 23.0, 27.0, 27.0, 3.0, 27.0, 13.0, 2.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 13.0, 23.0, 23.0, 27.0, 23.0, 23.0, 0.0, 23.0, 27.0, 27.0, 24.0, 13.0, 27.0, 23.0, 27.0, 13.0, 27.0, 27.0, 27.0, 13.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 27.0, 27.0, 27.0, 0.0, 27.0, 23.0, 0.0, 27.0, 23.0, 23.0, 0.0, 27.0, 27.0, 27.0, 27.0, 0.0, 27.0, 27.0, 23.0, 27.0, 23.0, 23.0, 13.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 27.0, 23.0, 27.0, 27.0, 23.0, 27.0, 23.0, 27.0, 23.0, 27.0, 23.0, 23.0, 27.0, 13.0, 27.0, 1.0, 27.0, 0.0, 23.0, 23.0, 27.0, 27.0, 27.0, 27.0, 23.0, 13.0, 27.0, 13.0, 13.0, 27.0, 23.0, 1.0, 26.0, 23.0, 23.0, 27.0, 27.0, 27.0, 13.0, 23.0, 3.0, 23.0, 13.0, 13.0, 25.0, 24.0, 2.0, 23.0, 13.0, 23.0, 13.0, 25.0, 1.0, 3.0, 2.0, 23.0, 1.0, 13.0, 23.0, 25.0, 2.0, 24.0, 23.0, 2.0, 999, 25.0, 0.0, 2.0, 25.0, 23.0, 1.0, 2.0, 13.0, 1.0, 13.0, 25.0, 2.0, 2.0, 13.0, 24.0, 3.0, 23.0, 25.0, 2.0, 13.0, 25.0, 27.0, 25.0, 13.0, 23.0, 2.0, 1.0, 24.0, 13.0, 23.0, 3.0, 25.0, 13.0, 1.0, 13.0, 25.0, 2.0, 13.0, 13.0, 2.0, 13.0, 2.0, 23.0, 2.0, 2.0, 27.0, 13.0, 13.0, 13.0, 1.0, 13.0, 23.0, 25.0, 3.0, 13.0, 23.0, 23.0, 13.0, 999, 3.0, 999, 13.0, 23.0, 23.0, 23.0, 13.0, 3.0, 0.0, 23.0, 2.0, 1.0, 23.0, 23.0, 26.0, 13.0, 23.0, 13.0, 13.0, 25.0, 1.0, 2.0, 1.0, 2.0, 999, 13.0, 23.0, 13.0, 13.0, 0.0, 25.0, 25.0, 1.0, 3.0, 3.0, 23.0, 1.0, 999, 2.0, 13.0, 13.0, 13.0, 25.0, 2.0, 2.0, 2.0, 23.0, 25.0, 23.0, 3.0, 13.0, 2.0, 25.0, 1.0, 25.0, 1.0, 13.0, 23.0, 23.0, 13.0, 23.0, 2.0, 2.0, 1.0, 25.0, 13.0, 3.0, 23.0, 25.0, 999, 13.0, 2.0, 13.0, 23.0, 23.0, 27.0, 13.0, 13.0, 23.0, 13.0, 25.0, 25.0, 2.0, 24.0, 13.0, 0.0, 0.0, 13.0, 23.0, 2.0, 13.0, 2.0, 13.0, 25.0, 23.0, 2.0, 1.0, 23.0, 2.0, 23.0, 25.0, 3.0, 2.0, 23.0, 23.0, 13.0, 23.0, 2.0, 23.0, 13.0, 23.0, 25.0, 23.0, 13.0, 2.0, 23.0, 13.0, 1.0, 2.0, 13.0, 999, 23.0, 13.0, 13.0, 3.0, 23.0, 13.0, 2.0, 13.0, 13.0, 13.0, 2.0, 2.0, 13.0, 23.0, 13.0, 13.0, 25.0, 13.0, 2.0, 26.0, 23.0, 13.0, 2.0, 2.0, 13.0, 23.0, 2.0, 13.0, 24.0, 25.0, 24.0, 2.0, 13.0, 25.0, 25.0, 13.0, 24.0, 13.0, 2.0, 13.0, 25.0, 23.0, 2.0, 13.0, 13.0, 23.0, 23.0, 13.0, 23.0, 13.0, 25.0, 23.0, 13.0, 2.0, 25.0, 26.0, 2.0, 27.0, 25.0, 25.0, 25.0, 25.0, 23.0, 27.0, 25.0, 25.0, 25.0, 2.0, 25.0, 2.0, 26.0, 27.0, 2.0, 2.0, 25.0, 25.0, 25.0, 2.0, 999, 2.0, 25.0, 23.0, 26.0, 25.0, 2.0, 23.0, 2.0, 25.0, 23.0, 2.0, 2.0, 25.0, 26.0, 25.0, 25.0, 25.0, 2.0, 26.0, 18.0, 2.0, 18.0, 25.0, 27.0, 27.0, 18.0, 26.0, 25.0, 18.0, 25.0, 25.0, 2.0, 999, 25.0, 25.0, 26.0, 2.0, 25.0, 26.0, 18.0, 2.0, 25.0, 25.0, 25.0, 27.0, 25.0, 25.0, 18.0, 13.0, 2.0, 25.0, 23.0, 18.0, 2.0, 2.0, 26.0, 25.0, 2.0, 26.0, 2.0, 2.0, 2.0, 2.0, 25.0, 23.0, 25.0, 25.0, 25.0, 25.0, 0.0, 27.0, 25.0, 13.0, 999, 26.0, 26.0, 25.0, 25.0, 2.0, 23.0, 18.0, 26.0, 25.0, 2.0, 26.0, 25.0, 27.0, 23.0, 25.0, 18.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 23.0, 25.0, 25.0, 25.0, 25.0, 26.0, 18.0, 25.0, 2.0, 25.0, 25.0, 25.0, 27.0, 18.0, 23.0, 18.0, 25.0, 23.0, 2.0, 27.0, 2.0, 23.0, 27.0, 27.0, 27.0, 23.0, 27.0, 18.0, 25.0, 2.0, 2.0, 25.0, 23.0, 25.0, 27.0, 2.0, 26.0, 25.0, 25.0, 999, 25.0, 2.0, 27.0, 25.0, 26.0, 27.0, 26.0, 2.0, 2.0, 27.0, 25.0, 23.0, 25.0, 25.0, 25.0, 25.0, 18.0, 27.0, 2.0, 999, 2.0, 26.0, 25.0, 25.0, 27.0, 25.0, 27.0, 26.0, 2.0, 23.0, 27.0, 2.0, 2.0, 3.0, 23.0, 25.0, 25.0, 2.0, 18.0, 25.0, 27.0, 999, 25.0, 26.0, 2.0, 2.0, 25.0, 999, 0.0, 25.0, 26.0, 26.0, 25.0, 23.0, 26.0, 25.0, 26.0, 0.0, 2.0, 2.0, 23.0, 2.0, 26.0, 27.0, 13.0, 25.0, 2.0, 27.0, 13.0, 26.0, 999, 2.0, 25.0, 2.0, 2.0, 25.0, 23.0, 2.0, 25.0, 25.0, 25.0, 23.0, 26.0, 23.0, 27.0, 27.0, 25.0, 25.0, 25.0, 2.0, 27.0, 18.0, 25.0, 13.0, 26.0, 2.0, 25.0, 23.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 28.0, 999, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 2.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 2.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 27.0, 28.0, 28.0, 28.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 28.0, 26.0, 26.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 23.0, 5.0, 23.0, 23.0, 23.0, 999, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 999, 23.0, 15.0, 23.0, 5.0, 23.0, 999, 23.0, 23.0, 23.0, 23.0, 23.0, 5.0, 5.0, 5.0, 23.0, 999, 23.0, 999, 5.0, 5.0, 999, 23.0, 23.0, 23.0, 23.0, 7.0, 23.0, 23.0, 23.0, 23.0, 999, 23.0, 15.0, 23.0, 23.0, 23.0, 5.0, 23.0, 23.0, 5.0, 23.0, 23.0, 23.0, 5.0, 999, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 5.0, 23.0, 5.0, 23.0, 5.0, 23.0, 23.0, 999, 7.0, 5.0, 7.0, 23.0, 23.0, 5.0, 7.0, 23.0, 23.0, 23.0, 23.0, 23.0, 5.0, 23.0, 23.0, 23.0, 999, 5.0, 23.0, 23.0, 23.0, 23.0, 999, 999, 23.0, 23.0, 999, 7.0, 22.0, 999, 23.0, 23.0, 23.0, 999, 999, 15.0, 23.0, 23.0, 999, 23.0, 7.0, 23.0, 5.0, 999, 15.0, 23.0, 23.0, 5.0, 5.0, 23.0, 5.0, 999, 23.0, 5.0, 23.0, 23.0, 23.0, 23.0, 23.0, 7.0, 23.0, 23.0, 15.0, 7.0, 999, 23.0, 5.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 999, 23.0, 999, 5.0, 23.0, 23.0, 999, 22.0, 23.0, 23.0, 999, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 5.0, 23.0, 999, 23.0, 23.0, 5.0, 23.0, 23.0, 999, 5.0, 23.0, 23.0, 5.0, 999, 23.0, 23.0, 23.0, 23.0, 15.0, 23.0, 23.0, 999, 23.0, 23.0, 999, 23.0, 999, 23.0, 15.0, 999, 23.0, 23.0, 23.0, 5.0, 5.0, 23.0, 999, 5.0, 23.0, 23.0, 999, 23.0, 23.0, 23.0, 23.0, 999, 999, 5.0, 23.0, 23.0, 23.0, 23.0, 5.0, 5.0, 7.0, 23.0, 999, 23.0, 23.0, 23.0, 23.0, 999, 15.0, 5.0, 5.0, 23.0, 23.0, 23.0, 999, 23.0, 23.0, 22.0, 23.0, 23.0, 23.0, 23.0, 5.0, 23.0, 999, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 15.0, 999, 23.0, 5.0, 25.0, 23.0, 25.0, 2.0, 999, 999, 2.0, 23.0, 25.0, 999, 24.0, 25.0, 999, 2.0, 2.0, 999, 25.0, 2.0, 999, 25.0, 25.0, 2.0, 25.0, 25.0, 23.0, 2.0, 25.0, 25.0, 23.0, 999, 999, 23.0, 2.0, 2.0, 999, 999, 999, 23.0, 23.0, 999, 999, 999, 999, 999, 999, 25.0, 999, 999, 25.0, 25.0, 18.0, 999, 18.0, 23.0, 25.0, 23.0, 24.0, 2.0, 999, 27.0, 23.0, 18.0, 2.0, 999, 2.0, 2.0, 28.0, 999, 18.0, 23.0, 2.0, 23.0, 999, 999, 24.0, 25.0, 27.0, 999, 999, 1.0, 999, 23.0, 25.0, 28.0, 23.0, 18.0, 999, 23.0, 27.0, 25.0, 23.0, 23.0, 28.0, 25.0, 999, 18.0, 999, 25.0, 999, 23.0, 23.0, 18.0, 25.0, 2.0, 999, 24.0, 24.0, 18.0, 999, 18.0, 999, 25.0, 999, 23.0, 23.0, 23.0, 2.0, 999, 25.0, 2.0, 999, 23.0, 18.0, 2.0, 23.0, 2.0, 2.0, 28.0, 23.0, 999, 999, 999, 2.0, 2.0, 2.0, 999, 28.0, 18.0, 999, 25.0, 999, 23.0, 23.0, 23.0, 18.0, 999, 2.0, 25.0, 13.0, 25.0, 27.0, 999, 2.0, 18.0, 24.0, 25.0, 999, 999, 25.0, 23.0, 27.0, 25.0, 2.0, 25.0, 999, 999, 2.0, 28.0, 2.0, 25.0, 999, 23.0, 25.0, 18.0, 23.0, 2.0, 999, 999, 2.0, 2.0, 23.0, 24.0, 2.0, 999, 18.0, 2.0, 25.0, 2.0, 23.0, 25.0, 2.0, 23.0, 23.0, 2.0, 999, 18.0, 2.0, 23.0, 13.0, 25.0, 24.0, 25.0, 25.0, 27.0, 999, 18.0, 23.0, 999, 2.0, 25.0, 24.0, 28.0, 25.0, 23.0, 18.0, 999, 25.0, 999, 25.0, 23.0, 28.0, 23.0, 2.0, 25.0, 18.0, 2.0, 18.0, 2.0, 25.0, 2.0, 999, 25.0, 999, 18.0, 2.0, 999, 2.0, 24.0, 999, 23.0, 2.0, 2.0, 18.0, 2.0, 999, 999, 2.0, 23.0, 25.0, 23.0, 2.0, 999, 28.0, 25.0, 23.0, 999, 25.0, 23.0, 27.0, 999, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 999, 999, 26.0, 26.0, 999, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 999, 999, 999, 26.0, 999, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 999, 26.0, 26.0, 999, 999, 999, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 999, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 999, 26.0, 26.0, 999, 999, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 999, 999, 999, 999, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 26.0, 999, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 999, 999, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 999, 26.0, 999, 999, 26.0, 26.0, 26.0, 999, 26.0, 26.0, 26.0, 999, 999, 26.0, 26.0, 26.0, 26.0, 999, 999, 26.0, 26.0, 999, 999, 26.0, 26.0, 999, 999, 26.0, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 999, 26.0, 999, 999, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 22.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 24.0, 24.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 24.0, 22.0, 22.0, 24.0, 24.0, 22.0, 22.0, 24.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 22.0, 22.0, 24.0, 22.0, 24.0, 24.0, 24.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 22.0, 22.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 22.0, 24.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 24.0, 24.0, 24.0, 22.0, 24.0, 22.0, 22.0, 24.0, 22.0, 22.0, 24.0, 22.0, 22.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 22.0, 24.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 22.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 24.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 22.0, 22.0, 22.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 24.0, 22.0, 22.0, 22.0, 24.0, 24.0, 22.0, 24.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 22.0, 22.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 24.0, 22.0, 22.0, 24.0, 22.0, 22.0, 22.0, 24.0, 24.0, 22.0, 24.0, 22.0, 24.0, 24.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0]\n",
      "=== Data Distribution ===\n",
      "Class 999: 1996 samples\n",
      "Class 27.0: 1129 samples\n",
      "Class 22.0: 719 samples\n",
      "Class 21.0: 119 samples\n",
      "Class 0.0: 391 samples\n",
      "Class 26.0: 1280 samples\n",
      "Class 15.0: 131 samples\n",
      "Class 13.0: 233 samples\n",
      "Class 1.0: 114 samples\n",
      "Class 2.0: 253 samples\n",
      "Class 24.0: 285 samples\n",
      "Class 3.0: 27 samples\n",
      "Class 23.0: 351 samples\n",
      "Class 25.0: 172 samples\n",
      "Class 18.0: 39 samples\n",
      "Class 28.0: 254 samples\n",
      "Class 5.0: 38 samples\n",
      "Class 7.0: 9 samples\n",
      "Dataset: demo\n",
      "Accuracy: 0.23023872679045093\n"
     ]
    }
   ],
   "source": [
    "# 主流程入口\n",
    "if __name__ == '__main__':\n",
    "    print('=== Initializing ===')\n",
    "    # 获取当前类别\n",
    "    curr_lab = make_lab(label)\n",
    "    # 训练初始模型\n",
    "    mod_ls, thred_ls, class_ls = train(data, label, curr_lab)\n",
    "    \n",
    "    res_ls = []  # 预测结果列表\n",
    "    # 流式数据逐步推理与模型更新\n",
    "    for i5 in range(streamdata.shape[0]):\n",
    "        # 每处理完一个新类，更新模型\n",
    "        if i5 % b_size == 0 and int(i5 / b_size) > train_num:\n",
    "            updatedata = np.concatenate([data, streamdata[:i5]], axis=0)\n",
    "            updatelabel = np.concatenate([label, gtlabel[:i5]], axis=0)\n",
    "            curr_lab = make_lab(updatelabel)\n",
    "            print('Current labels:', curr_lab)\n",
    "            mod_ls, thred_ls, class_ls = train(updatedata, updatelabel, curr_lab) \n",
    "            print('*** Update model ***')\n",
    "            print(f'Number of models: {len(mod_ls)}')\n",
    "            print(f'Thresholds: {thred_ls}')\n",
    "            print(f'Class labels: {class_ls}')\n",
    "        # 对当前样本用所有模型计算重构误差\n",
    "        data_input = torch.from_numpy(streamdata[i5]).float()\n",
    "        mse_test = []\n",
    "        for model in mod_ls:\n",
    "            mod_eva = model.eval()\n",
    "            pred = model(data_input)\n",
    "            loss = loss_func(pred, data_input)\n",
    "            mse_test.append(float(loss.detach().numpy()))\n",
    "        # 判断是否为新类\n",
    "        cand_res = np.array(mse_test)[np.array(mse_test) < np.array(thred_ls)]\n",
    "        if len(cand_res) == 0:\n",
    "            res_ls.append(999)\n",
    "        else:\n",
    "            min_loss_res = cand_res.min()\n",
    "            res_ls.append(class_ls[mse_test.index(min_loss_res)])\n",
    "    print()\n",
    "    print(\"Number of models:\", len(mod_ls))\n",
    "    print(\"Thresholds:\", thred_ls)\n",
    "    print(\"Class labels:\", class_ls)\n",
    "    # Output complete res_ls results\n",
    "    print(\"=== Prediction Results ===\")\n",
    "    print(\"res_ls contents:\", res_ls)\n",
    "\n",
    "    # Show data distribution in res_ls\n",
    "    res_distribution = Counter(res_ls)\n",
    "    print(\"=== Data Distribution ===\")\n",
    "    for class_label, count in res_distribution.items():\n",
    "        print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "    res_copy = []\n",
    "    res_copy = res_ls\n",
    "\n",
    "    # 对新类样本，将999替换为真实标签\n",
    "    for ii in range(train_num + newclass_num):\n",
    "        if ii >= train_num:\n",
    "            rep_npy = np.array(res_ls[test_per_class * ii : test_per_class * (ii + 1)])\n",
    "            rep_npy2 = rep_npy.copy()\n",
    "            rep_npy[rep_npy2==999] = allIndex[ii]\n",
    "            res_ls[test_per_class * ii:test_per_class * (ii + 1)] = list(rep_npy)\n",
    "    \n",
    "    # 计算准确率\n",
    "    y_pred = np.array(res_ls)\n",
    "    y_true = gtlabel[:len(res_ls)].copy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print('Dataset:', data_name)\n",
    "    print('Accuracy:', acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
