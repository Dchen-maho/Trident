{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b13ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_process.py\n",
    "# 主程序入口，进行数据加载、预处理、模型训练与测试，并评估分类准确率\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch import nn\n",
    "from data_loader import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from autoencoder import *\n",
    "from evt import *\n",
    "import argparse\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb7b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Github\\Trident\\code\\data_loader.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.replace([np.inf, -np.inf], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Attack Type\n",
      "6     1440906\n",
      "11    1083360\n",
      "8      819305\n",
      "9      808928\n",
      "17     535121\n",
      "16     406024\n",
      "1      219809\n",
      "19     191353\n",
      "20     177756\n",
      "7       90510\n",
      "27      74423\n",
      "18      61784\n",
      "12      57249\n",
      "4       56535\n",
      "13      35955\n",
      "21      26834\n",
      "22      19656\n",
      "24      16493\n",
      "15      14358\n",
      "5        5673\n",
      "10       4692\n",
      "14       2639\n",
      "2        1187\n",
      "25       1097\n",
      "3        1055\n",
      "28        779\n",
      "0         659\n",
      "23        444\n",
      "26        277\n",
      "Name: count, dtype: int64\n",
      "=== Data Loading Time ===\n",
      "Data loading time: 0:00:23.783021\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子，保证实验可复现\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# 解析命令行参数，支持自定义数据集名称\n",
    "default_data_name = 'demo'\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--data_name', type = str, default = default_data_name, help = 'data name')\n",
    "# args = parser.parse_args()\n",
    "# data_name = args.data_name\n",
    "data_name = default_data_name\n",
    "\n",
    "# 加载数据集，并进行标准化\n",
    "# data_load: 特征数据, label_load: 标签\n",
    "data_load, label_load = read_dataset(data_name)\n",
    "data_load = StandardScaler().fit_transform(data_load)\n",
    "\n",
    "# 统计每个类别的样本数，确定训练/测试划分\n",
    "count_number = Counter(label_load)\n",
    "min_num = np.array(list(count_number.values())).min()  # 最小类别样本数\n",
    "test_per_class = 260  # 每类测试样本数\n",
    "num_per_class = min_num - test_per_class  # 每类训练样本数\n",
    "dim = data_load.shape[1]  # 特征维度\n",
    "b_size = test_per_class   # 批量大小\n",
    "loss_func = nn.MSELoss()  # 损失函数\n",
    "\n",
    "sum_num = len(set(list((label_load))))  # 类别总数\n",
    "train_num = 10  # 训练类别数（只用一个类别做已知，其余为新类）\n",
    "newclass_num = sum_num - train_num  # 新类别数\n",
    "\n",
    "# 打乱数据顺序\n",
    "shun = list(range(data_load.shape[0]))\n",
    "random.shuffle(shun)\n",
    "data_load = data_load[shun]\n",
    "label_load = label_load[shun]\n",
    "\n",
    "# 随机排列类别索引\n",
    "allIndex = np.random.permutation(train_num + newclass_num)\n",
    "# 计算数据加载部分耗费的时间\n",
    "data_loading_end = time.time()\n",
    "data_loading_time = data_loading_end - start_time\n",
    "print(f\"=== Data Loading Time ===\")\n",
    "print(f\"Data loading time: {str(timedelta(seconds=data_loading_time))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb67499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct labels in 'gtlabel': [27. 16. 12. 22.  8.  9. 21.  0. 26. 13. 15. 11. 17.  1.  4.  5.  2. 24.\n",
      "  3. 23. 25. 18. 28. 20.  7. 10. 14. 19.  6.]\n",
      "\n",
      "=== Data Preprocessing Time ===\n",
      "Preprocessing time: 0:00:01.326109\n"
     ]
    }
   ],
   "source": [
    "# 构建训练集（只包含已知类别）\n",
    "data = np.zeros((num_per_class * (train_num), dim))\n",
    "label = np.zeros(num_per_class * (train_num))\n",
    "for pos in range(train_num):\n",
    "    i = allIndex[pos]\n",
    "    data[pos * num_per_class:(pos + 1) * num_per_class,:] = data_load[label_load==i][0:num_per_class, :]\n",
    "    label[pos * num_per_class:(pos + 1) * num_per_class] = i\n",
    "\n",
    "\n",
    "# 构建流式测试集（包含所有类别，已知类标记为原标签，未知类标记为999）\n",
    "streamdata = np.zeros((test_per_class * (train_num + newclass_num), dim))\n",
    "streamlabel = np.zeros(test_per_class * (train_num + newclass_num))\n",
    "gtlabel = np.zeros(test_per_class * (train_num + newclass_num))\n",
    "for pos in range(train_num + newclass_num):\n",
    "    i = allIndex[pos]\n",
    "    streamdata[pos * test_per_class:(pos + 1) * test_per_class,:] = data_load[label_load==i][-test_per_class:, :]\n",
    "    gtlabel[pos * test_per_class:(pos + 1) * test_per_class] = i\n",
    "    if pos < train_num:\n",
    "        streamlabel[pos * test_per_class:(pos+1) * test_per_class] = i\n",
    "    else:\n",
    "        streamlabel[pos * test_per_class:(pos + 1) * test_per_class] = 999\n",
    "        \n",
    "# 输出 gtlabel 中按出现顺序的不同标签\n",
    "unique_labels = pd.Series(gtlabel).unique()\n",
    "print(\"Distinct labels in 'gtlabel':\", unique_labels)\n",
    "\n",
    "\n",
    "# 根据标签统计，筛选样本数大于50的类别\n",
    "# 返回当前存在的类别列表\n",
    "def make_lab(label):\n",
    "    xianyou = pd.DataFrame(label).value_counts()\n",
    "    curr_lab = []\n",
    "    for j1 in xianyou.keys():\n",
    "        for i in range(train_num):\n",
    "            if (xianyou[j1] > 50) and (j1[0] == allIndex[i]):\n",
    "                curr_lab.append(j1[0])\n",
    "                break\n",
    "        # if xianyou[j1] > 50:\n",
    "        #     curr_lab.append(j1[0])\n",
    "    return curr_lab\n",
    "\n",
    "# 针对每个类别训练自编码器模型，并用SPOT方法确定阈值\n",
    "# 返回模型列表、阈值列表、类别列表\n",
    "def train(data, label, curr_lab):\n",
    "    mod_ls = []\n",
    "    thred_ls = []\n",
    "    class_ls = []\n",
    "    batch = 100\n",
    "    epoch = 400\n",
    "    y_in, y1, y2, y3, y4 = data_load.shape[1], 256, 128, 64, 32\n",
    "    for i in curr_lab:\n",
    "        class_ls.append(i)\n",
    "        model = Autoencoder(y_in, y1, y2, y3, y4)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 5e-4)\n",
    "        # 训练自编码器\n",
    "        for i2 in range(epoch):\n",
    "            shun = list(range(data[label==i].shape[0]))\n",
    "            random.shuffle(shun)\n",
    "            for i3 in range(int(data[label==i].shape[0] / batch)):\n",
    "                data_input = torch.from_numpy(data[label==i][shun][i3 * batch : (i3+1) * batch]).float()\n",
    "                pred = model(data_input)\n",
    "                loss = loss_func(pred, data_input)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        mod_eva = model.eval()\n",
    "        mod_ls.append(model)\n",
    "        # 计算重构误差，用于阈值确定\n",
    "        mse_ls = []\n",
    "        for i4 in range(int(data[label==i].shape[0] / batch)):\n",
    "            data_input = torch.from_numpy(data[label==i][i4 * batch : (i4+1) * batch]).float()\n",
    "            pred = model(data_input)\n",
    "            for i5 in range(pred.shape[0]):\n",
    "                loss = loss_func(pred[i5], data_input[i5])\n",
    "                mse_ls.append(float(loss.detach().numpy()))\n",
    "        data_input = torch.from_numpy(data[label==i][(i4 + 1) * batch:]).float()\n",
    "        pred = model(data_input)\n",
    "        for i5 in range(pred.shape[0]):\n",
    "            loss = loss_func(pred[i5], data_input[i5])\n",
    "            mse_ls.append(float(loss.detach().numpy()))\n",
    "        loss_list_use = np.array(mse_ls)\n",
    "        q = 5e-2 # 风险参数，可调\n",
    "        s = SPOT(q)\n",
    "        s.fit(loss_list_use, loss_list_use)\n",
    "        s.initialize()\n",
    "        results = s.run_simp()\n",
    "        # 阈值选取\n",
    "        if results['thresholds'][0] > 0:\n",
    "            thred_ls.append(results['thresholds'][0])\n",
    "        else:\n",
    "            thred_ls.append(np.sort(s.init_data)[int(0.85 * s.init_data.size)])\n",
    "    return mod_ls, thred_ls, class_ls\n",
    "\n",
    "# 计算数据预处理部分耗费的时间\n",
    "preprocessing_end = time.time()\n",
    "preprocessing_time = preprocessing_end - data_loading_end\n",
    "\n",
    "print(f\"\\n=== Data Preprocessing Time ===\")\n",
    "print(f\"Preprocessing time: {str(timedelta(seconds=preprocessing_time))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f150f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initializing ===\n",
      "Current labels: [0.0, 8.0, 9.0, 12.0, 13.0, 16.0, 21.0, 26.0, 22.0, 27.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.023231918370281577), np.float64(0.0005494977231137455), np.float64(0.00022509180416818708), np.float64(0.002455619770093156), np.float64(0.003109994111582637), np.float64(0.0007888273685239255), np.float64(0.013932541012763977), np.float64(0.004780124965164438), np.float64(0.0058024306781589985), np.float64(0.0015240674658485807)]\n",
      "Class labels: [0.0, 8.0, 9.0, 12.0, 13.0, 16.0, 21.0, 26.0, 22.0, 27.0]\n",
      "Current labels: [0.0, 8.0, 9.0, 12.0, 26.0, 13.0, 16.0, 21.0, 27.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.0068015911554881285), np.float64(0.0004245529416948557), np.float64(0.0030180712606058396), np.float64(0.005192212218018338), np.float64(0.008017252798347307), np.float64(0.005257962737232447), np.float64(0.0004405885993037373), np.float64(0.02261834777891636), np.float64(0.0012041579656070223), np.float64(0.007181807924079929)]\n",
      "Class labels: [0.0, 8.0, 9.0, 12.0, 26.0, 13.0, 16.0, 21.0, 27.0, 22.0]\n",
      "Current labels: [0.0, 8.0, 9.0, 12.0, 13.0, 26.0, 16.0, 22.0, 21.0, 27.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.0075965732683285995), np.float64(0.00043072871631011367), np.float64(0.00022592001187149435), np.float64(0.005478172017334453), np.float64(0.0035667335614562035), np.float64(0.002346070575528416), np.float64(0.000602023268584162), np.float64(0.00587231433019042), np.float64(0.005480920430272818), np.float64(0.012591248013919192)]\n",
      "Class labels: [0.0, 8.0, 9.0, 12.0, 13.0, 26.0, 16.0, 22.0, 21.0, 27.0]\n",
      "Current labels: [0.0, 8.0, 12.0, 9.0, 16.0, 13.0, 26.0, 27.0, 22.0, 21.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.0691524014596152), np.float64(0.0012702986199903087), np.float64(0.004578090643116485), np.float64(0.0030095909155104486), np.float64(0.0005802244995720685), np.float64(0.0033856492955237627), np.float64(0.0056954880122604135), np.float64(0.012556284661788628), np.float64(0.007403758820146322), np.float64(0.006508038379251957)]\n",
      "Class labels: [0.0, 8.0, 12.0, 9.0, 16.0, 13.0, 26.0, 27.0, 22.0, 21.0]\n",
      "Current labels: [0.0, 9.0, 8.0, 12.0, 22.0, 16.0, 13.0, 26.0, 27.0, 21.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.003921872742447893), np.float64(0.00022338464623317122), np.float64(0.0004262786533217877), np.float64(0.00421391986868505), np.float64(0.02427145279943943), np.float64(0.0006265590782277286), np.float64(0.0032116647344082594), np.float64(0.002052233304333309), np.float64(0.005475885527696507), np.float64(0.005938734859228134)]\n",
      "Class labels: [0.0, 9.0, 8.0, 12.0, 22.0, 16.0, 13.0, 26.0, 27.0, 21.0]\n",
      "Current labels: [0.0, 12.0, 9.0, 8.0, 21.0, 22.0, 16.0, 13.0, 26.0, 27.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.0062867142260074615), np.float64(0.0009004336316138506), np.float64(0.0029319460303324583), np.float64(0.0004443320503924042), np.float64(0.006697461787227294), np.float64(0.0509942998978009), np.float64(0.0005418299697339535), np.float64(0.001971002546398138), np.float64(0.0029222817317553027), np.float64(0.015793907180713065)]\n",
      "Class labels: [0.0, 12.0, 9.0, 8.0, 21.0, 22.0, 16.0, 13.0, 26.0, 27.0]\n",
      "Current labels: [0.0, 9.0, 12.0, 8.0, 26.0, 21.0, 22.0, 16.0, 13.0, 27.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.015933798929430525), np.float64(0.00019090689602307975), np.float64(0.005597361985367824), np.float64(0.0003116975479348517), np.float64(0.013905253063577688), np.float64(0.01057392485076782), np.float64(0.006649157032370567), np.float64(0.0006136076990514994), np.float64(0.0015468965421967058), np.float64(0.005763948734582566)]\n",
      "Class labels: [0.0, 9.0, 12.0, 8.0, 26.0, 21.0, 22.0, 16.0, 13.0, 27.0]\n",
      "Current labels: [0.0, 8.0, 27.0, 13.0, 12.0, 9.0, 22.0, 26.0, 21.0, 16.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.001586566149477997), np.float64(0.0004137566138524562), np.float64(0.008136856165808967), np.float64(0.003547433763742447), np.float64(0.004796777543304917), np.float64(0.000178021946339868), np.float64(0.006804254371672869), np.float64(0.004041034903259785), np.float64(0.008990280521822668), np.float64(0.0007077861810103059)]\n",
      "Class labels: [0.0, 8.0, 27.0, 13.0, 12.0, 9.0, 22.0, 26.0, 21.0, 16.0]\n",
      "Current labels: [0.0, 13.0, 8.0, 27.0, 26.0, 12.0, 9.0, 22.0, 16.0, 21.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.004376751231722152), np.float64(0.0035950862802565098), np.float64(8.211906531631081e-05), np.float64(0.0033019330400510197), np.float64(0.00033217028422523765), np.float64(0.005330731275960589), np.float64(0.00028483037021942437), np.float64(0.004153348583712236), np.float64(0.0006416080868802965), np.float64(0.0067363763228058815)]\n",
      "Class labels: [0.0, 13.0, 8.0, 27.0, 26.0, 12.0, 9.0, 22.0, 16.0, 21.0]\n",
      "Current labels: [0.0, 13.0, 8.0, 9.0, 26.0, 22.0, 21.0, 12.0, 27.0, 16.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.009481740184128284), np.float64(0.003057632129639387), np.float64(0.0004978717188350856), np.float64(0.0028825749874858133), np.float64(0.009735964972756278), np.float64(0.005675425752997398), np.float64(0.006389119196683168), np.float64(0.005202116395461833), np.float64(0.00905877824433632), np.float64(0.0005867832223884761)]\n",
      "Class labels: [0.0, 13.0, 8.0, 9.0, 26.0, 22.0, 21.0, 12.0, 27.0, 16.0]\n",
      "Current labels: [0.0, 12.0, 13.0, 9.0, 8.0, 27.0, 26.0, 22.0, 21.0, 16.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.005432788207472905), np.float64(0.005625530055726653), np.float64(0.001470969642489447), np.float64(0.00018697255291044712), np.float64(0.00042097623512948445), np.float64(0.003913450210408172), np.float64(0.01136223290479852), np.float64(0.1763849002973643), np.float64(0.006590866018086672), np.float64(0.0005210735835134983)]\n",
      "Class labels: [0.0, 12.0, 13.0, 9.0, 8.0, 27.0, 26.0, 22.0, 21.0, 16.0]\n",
      "Current labels: [0.0, 16.0, 13.0, 12.0, 9.0, 8.0, 27.0, 26.0, 22.0, 21.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.013044787825058812), np.float64(0.000551705074030906), np.float64(0.006886855237785693), np.float64(0.005540472463960296), np.float64(0.002926512031034121), np.float64(0.0008838886237436394), np.float64(0.007243453099276386), np.float64(0.0010402466434985816), np.float64(0.002381288014770706), np.float64(0.019126144953087836)]\n",
      "Class labels: [0.0, 16.0, 13.0, 12.0, 9.0, 8.0, 27.0, 26.0, 22.0, 21.0]\n",
      "Current labels: [0.0, 8.0, 26.0, 16.0, 13.0, 12.0, 9.0, 22.0, 27.0, 21.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.007123274728655815), np.float64(0.00045978432171978056), np.float64(0.016423137277231832), np.float64(0.0006641170475631952), np.float64(0.0005550806139519148), np.float64(0.003935177889721407), np.float64(0.00026928266743198037), np.float64(0.00624862452968955), np.float64(0.007816007976968013), np.float64(0.01353606808405492)]\n",
      "Class labels: [0.0, 8.0, 26.0, 16.0, 13.0, 12.0, 9.0, 22.0, 27.0, 21.0]\n",
      "Current labels: [0.0, 9.0, 8.0, 26.0, 21.0, 16.0, 13.0, 12.0, 22.0, 27.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.0887800074461639), np.float64(0.00015056136180646718), np.float64(0.00036551832454279065), np.float64(0.005266165078436578), np.float64(0.0052372547797858715), np.float64(0.0006200264906510711), np.float64(0.0031230251770466566), np.float64(0.0017090324765033828), np.float64(0.010623400461165862), np.float64(0.015086740884246878)]\n",
      "Class labels: [0.0, 9.0, 8.0, 26.0, 21.0, 16.0, 13.0, 12.0, 22.0, 27.0]\n",
      "Current labels: [0.0, 8.0, 9.0, 27.0, 26.0, 21.0, 16.0, 13.0, 12.0, 22.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.05416344093216012), np.float64(0.0004023106303066015), np.float64(0.00021295376063790172), np.float64(0.0022881435873750196), np.float64(0.00964181147636858), np.float64(0.007162152789533138), np.float64(0.0005088007892481983), np.float64(0.0009420241002507275), np.float64(0.005010696667747899), np.float64(0.006008828990161419)]\n",
      "Class labels: [0.0, 8.0, 9.0, 27.0, 26.0, 21.0, 16.0, 13.0, 12.0, 22.0]\n",
      "Current labels: [0.0, 9.0, 8.0, 22.0, 27.0, 26.0, 21.0, 16.0, 13.0, 12.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.007218669068968271), np.float64(0.00024042741279117763), np.float64(0.0004012882709503174), np.float64(0.018332140010703664), np.float64(0.008069257783698627), np.float64(0.0586326721806807), np.float64(0.006475410871636627), np.float64(0.00045241147745400667), np.float64(0.0020125841425494354), np.float64(0.005539602302407631)]\n",
      "Class labels: [0.0, 9.0, 8.0, 22.0, 27.0, 26.0, 21.0, 16.0, 13.0, 12.0]\n",
      "Current labels: [0.0, 8.0, 9.0, 21.0, 22.0, 27.0, 26.0, 13.0, 16.0, 12.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.09194746526151143), np.float64(0.0006422159027714321), np.float64(0.002557642775757376), np.float64(0.007800942752510309), np.float64(0.030954279447393672), np.float64(0.005856013315464635), np.float64(0.00465908320620656), np.float64(0.004334276542067528), np.float64(0.0004956215852871537), np.float64(0.005148075731115372)]\n",
      "Class labels: [0.0, 8.0, 9.0, 21.0, 22.0, 27.0, 26.0, 13.0, 16.0, 12.0]\n",
      "Current labels: [0.0, 12.0, 9.0, 8.0, 21.0, 22.0, 27.0, 26.0, 16.0, 13.0]\n",
      "*** Update model ***\n",
      "Number of models: 10\n",
      "Thresholds: [np.float64(0.007538456004112959), np.float64(0.00487532749021624), np.float64(0.00020677507563959807), np.float64(0.0004805031348951161), np.float64(0.017340153699871016), np.float64(0.006077697034925222), np.float64(0.006935344077646732), np.float64(0.005071151535958052), np.float64(0.0005587016348727047), np.float64(0.0036764542342823396)]\n",
      "Class labels: [0.0, 12.0, 9.0, 8.0, 21.0, 22.0, 27.0, 26.0, 16.0, 13.0]\n",
      "\n",
      "=== Training Time ===\n",
      "Training time: 0:07:18.070752\n",
      "\n",
      "=== Known Class Predictions ===\n",
      "Number of samples: 4469\n",
      "Accuracy: 0.0000\n",
      "\n",
      "=== Unknown Class Predictions ===\n",
      "Number of samples: 3071\n",
      "Adjusted Rand Index (ARI): 0.3097\n",
      "\n",
      "=== DBSCAN Time ===\n",
      "Clustering time: 0:00:01.361805\n",
      "\n",
      "=== Total Time ===\n",
      "Total execution time: 0:07:44.541687\n"
     ]
    }
   ],
   "source": [
    "# 主流程入口\n",
    "if __name__ == '__main__':\n",
    "    print('=== Initializing ===')\n",
    "    # 获取当前类别\n",
    "    curr_lab = make_lab(label)\n",
    "    # 训练初始模型\n",
    "    mod_ls, thred_ls, class_ls = train(data, label, curr_lab)\n",
    "    \n",
    "    res_ls = []  # 预测结果列表\n",
    "    # 流式数据逐步推理与模型更新\n",
    "    for i5 in range(streamdata.shape[0]):\n",
    "        # 每处理完一个新类，更新模型\n",
    "        if i5 % b_size == 0 and int(i5 / b_size) > train_num:\n",
    "            updatedata = np.concatenate([data, streamdata[:i5]], axis=0)\n",
    "            updatelabel = np.concatenate([label, gtlabel[:i5]], axis=0)\n",
    "            curr_lab = make_lab(updatelabel)\n",
    "            print('Current labels:', curr_lab)\n",
    "            mod_ls, thred_ls, class_ls = train(updatedata, updatelabel, curr_lab) \n",
    "            print('*** Update model ***')\n",
    "            print(f'Number of models: {len(mod_ls)}')\n",
    "            print(f'Thresholds: {thred_ls}')\n",
    "            print(f'Class labels: {class_ls}')\n",
    "        # 对当前样本用所有模型计算重构误差\n",
    "        data_input = torch.from_numpy(streamdata[i5]).float()\n",
    "        mse_test = []\n",
    "        for model in mod_ls:\n",
    "            mod_eva = model.eval()\n",
    "            pred = model(data_input)\n",
    "            loss = loss_func(pred, data_input)\n",
    "            mse_test.append(float(loss.detach().numpy()))\n",
    "        # 判断是否为新类\n",
    "        cand_res = np.array(mse_test)[np.array(mse_test) < np.array(thred_ls)]\n",
    "        if len(cand_res) == 0:\n",
    "            res_ls.append(999)\n",
    "        else:\n",
    "            min_loss_res = cand_res.min()\n",
    "            res_ls.append(class_ls[mse_test.index(min_loss_res)])\n",
    "    \n",
    "    # Calculate training and testing time\n",
    "    training_end = time.time()\n",
    "    training_time = training_end - preprocessing_end\n",
    "\n",
    "    print(f\"\\n=== Training Time ===\")\n",
    "    print(f\"Training time: {str(timedelta(seconds=training_time))}\")\n",
    "\n",
    "    # print()\n",
    "    # print(\"Number of models:\", len(mod_ls))\n",
    "    # print(\"Thresholds:\", thred_ls)\n",
    "    # print(\"Class labels:\", class_ls)\n",
    "    # Output complete res_ls results\n",
    "    # print(\"=== Prediction Results ===\")\n",
    "    # print(\"res_ls contents:\", res_ls)\n",
    "\n",
    "    # Show data distribution in res_ls\n",
    "    # res_distribution = Counter(res_ls)\n",
    "    # print(\"=== Data Distribution ===\")\n",
    "    # for class_label, count in res_distribution.items():\n",
    "    #     print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "    # 对新类样本，将999替换为真实标签\n",
    "    # for ii in range(train_num + newclass_num):\n",
    "    #     if ii >= train_num:\n",
    "    #         rep_npy = np.array(res_ls[test_per_class * ii : test_per_class * (ii + 1)])\n",
    "    #         rep_npy2 = rep_npy.copy()\n",
    "    #         rep_npy[rep_npy2==999] = allIndex[ii]\n",
    "    #         res_ls[test_per_class * ii:test_per_class * (ii + 1)] = list(rep_npy)\n",
    "    \n",
    "    # 计算准确率\n",
    "    # y_pred = np.array(res_ls)\n",
    "    # y_true = gtlabel[:len(res_ls)].copy()\n",
    "    # acc = accuracy_score(y_true, y_pred)\n",
    "    # print('Dataset:', data_name)\n",
    "    # print('Accuracy:', acc)\n",
    "\n",
    "    # Separate samples into known and unknown predictions\n",
    "    predict_known_features = []\n",
    "    predict_known_labels = []\n",
    "    predict_known_true_labels = []\n",
    "\n",
    "    predict_unknown_features = []\n",
    "    predict_unknown_labels = []\n",
    "    predict_unknown_true_labels = []\n",
    "    predict_known_indices = []\n",
    "\n",
    "    for i in range(test_per_class * train_num):\n",
    "        # Known class prediction\n",
    "        predict_known_features.append(streamdata[i])\n",
    "        predict_known_labels.append(res_ls[i])\n",
    "        predict_known_true_labels.append(gtlabel[i])\n",
    "        # Track the index in the original streamdata for known class predictions\n",
    "        predict_known_indices.append(i)\n",
    "\n",
    "\n",
    "    for i, pred_label in enumerate(res_ls):\n",
    "        if (i < test_per_class * train_num):\n",
    "            continue\n",
    "        if pred_label == 999:\n",
    "            # Unknown class prediction\n",
    "            predict_unknown_features.append(streamdata[i])\n",
    "            predict_unknown_labels.append(pred_label)\n",
    "            predict_unknown_true_labels.append(gtlabel[i])\n",
    "        else:\n",
    "            # Known class prediction\n",
    "            predict_known_features.append(streamdata[i])\n",
    "            predict_known_labels.append(999)\n",
    "            predict_known_true_labels.append(gtlabel[i])\n",
    "            # Track the index in the original streamdata for known class predictions\n",
    "            predict_known_indices.append(i)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    predict_known_features = np.array(predict_known_features)\n",
    "    predict_known_labels = np.array(predict_known_labels)\n",
    "    predict_known_true_labels = np.array(predict_known_true_labels)\n",
    "\n",
    "    predict_unknown_features = np.array(predict_unknown_features)\n",
    "    predict_unknown_labels = np.array(predict_unknown_labels)\n",
    "    predict_unknown_true_labels = np.array(predict_unknown_true_labels)\n",
    "\n",
    "    \n",
    "    # Calculate accuracy for known predictions\n",
    "    if len(predict_known_labels) > 0:\n",
    "        known_accuracy = accuracy_score(predict_known_true_labels, predict_known_labels)\n",
    "        print(\"\\n=== Known Class Predictions ===\")\n",
    "        print(f\"Number of samples: {len(predict_known_labels)}\")\n",
    "        print(f\"Accuracy: {known_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo known class predictions to evaluate.\")\n",
    "        \n",
    "    # Only proceed if we have unknown class predictions\n",
    "    if len(predict_unknown_labels) > 0:\n",
    "        print(\"\\n=== Unknown Class Predictions ===\")\n",
    "        print(f\"Number of samples: {len(predict_unknown_labels)}\")\n",
    "        \n",
    "        # Perform DBSCAN clustering on unknown samples\n",
    "        \n",
    "        # Normalize the features for better clustering\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(predict_unknown_features)\n",
    "        \n",
    "        # Apply DBSCAN clustering\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust parameters as needed\n",
    "        cluster_labels = dbscan.fit_predict(scaled_features)\n",
    "        \n",
    "        # Count number of clusters formed (excluding noise points labeled as -1)\n",
    "        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "        n_noise = list(cluster_labels).count(-1)\n",
    "        \n",
    "        # Calculate ARI between cluster labels and true labels\n",
    "        ari_score = adjusted_rand_score(predict_unknown_true_labels, cluster_labels)\n",
    "        print(f\"Adjusted Rand Index (ARI): {ari_score:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo unknown class predictions to cluster.\")\n",
    "    \n",
    "    # Calculate clustering time and total execution time\n",
    "    clustering_end = time.time()\n",
    "    clustering_time = clustering_end - training_end\n",
    "\n",
    "    print(f\"\\n=== DBSCAN Time ===\")\n",
    "    print(f\"Clustering time: {str(timedelta(seconds=clustering_time))}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n=== Total Time ===\")\n",
    "    total_time = clustering_end - start_time\n",
    "    print(f\"Total execution time: {str(timedelta(seconds=total_time))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
